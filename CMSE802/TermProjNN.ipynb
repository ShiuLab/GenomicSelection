{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.insert(1,'./packages')\n",
    "\n",
    "\n",
    "#Imports\n",
    "from __future__ import division, print_function\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class prediction:\n",
    "\n",
    "    def RF(X, Y, cv):\n",
    "        \"\"\" Predict trait using Random Forest \"\"\"\n",
    "        numberTrees = 100\n",
    "\n",
    "        Y_TRUE = []\n",
    "        Y_PRED = []\n",
    "        Y_TRUE_train = []\n",
    "        Y_PRED_train = []\n",
    "\n",
    "        mse = []\n",
    "        r2 = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Build and fit the RF Regressor \n",
    "        model = RandomForestRegressor(n_estimators=numberTrees, min_samples_leaf = 5, min_samples_split=20, max_depth = 10, max_features=0.33, random_state=42) \n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions (test and training sets)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "        Y_TRUE = np.append(Y_TRUE, y_test)\n",
    "        Y_PRED = np.append(Y_PRED, y_pred)\n",
    "        Y_TRUE_train = np.append(Y_TRUE_train, y_train)\n",
    "        Y_PRED_train = np.append(Y_PRED_train, y_pred_train)\n",
    "\n",
    "        mse = np.append(mse, (mean_squared_error(y_test, y_pred)))\n",
    "        r2 = np.append(r2, (r2_score(y_test, y_pred)))\n",
    "\n",
    "        return Y_TRUE, Y_PRED, Y_TRUE_train, Y_PRED_train, mse, r2\n",
    "            \n",
    "    def NN(X, Y):\n",
    "            \"\"\" Predict trait using Neural Networks \"\"\"\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "            Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain, Ytrain, test_size=0.2, random_state=0)\n",
    "            print(Xtrain.shape, Xval.shape, Xtest.shape, Ytrain.shape, Yval.shape, Ytest.shape)\n",
    "            Xshape = Xtrain.shape\n",
    "            #print('Training data')\n",
    "            #print(Xtrain[:,0])\n",
    "            #print(Xtrain[:,1])\n",
    "            #print(Ytrain)\n",
    "            # print(Ytest)\n",
    "            # NN structure\n",
    "            model = Sequential()\n",
    "            model.add(Dense(20, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            model.add(Dense(60, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            model.add(Dense(30, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            #model.add(Dense(27, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            #model.add(Dense(20, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            #model.add(Dense(20, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            #model.add(Dense(20, input_dim=8, activation='sigmoid',bias=True))\n",
    "            model.add(Dense(1, input_dim=Xshape[1], activation='sigmoid',bias=True))\n",
    "            # training rate\n",
    "            sgd = SGD(lr=1)\n",
    "            model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            history = LossHistory()\n",
    "            # train NN model\n",
    "            model.fit(Xtrain, Ytrain, batch_size=20, nb_epoch=1000, shuffle=True, validation_data=(Xval, Yval), callbacks=[history])\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Plot\n",
    "            plt.figure(1,figsize=(15, 5))\n",
    "            plt.subplot(121)\n",
    "            plt.plot(range(len(history.losses)), history.losses)\n",
    "            plt.xlabel(\"batch\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(122)\n",
    "            plt.plot(range(len(history.accuracies)), history.accuracies)\n",
    "            plt.xlabel(\"batch\")\n",
    "            plt.ylabel(\"acc\")\n",
    "            plt.grid()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "            \n",
    "            \n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get(\"loss\"))\n",
    "        self.accuracies.append(logs.get(\"acc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 8) (52, 8) (65, 8) (204,) (52,) (65,)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_199 (Dense)                (None, 20)            180         dense_input_49[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_200 (Dense)                (None, 60)            1260        dense_199[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_201 (Dense)                (None, 30)            1830        dense_200[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_202 (Dense)                (None, 1)             31          dense_201[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3301\n",
      "____________________________________________________________________________________________________\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1616 - acc: 0.8088 - val_loss: 0.1022 - val_acc: 0.8846\n",
      "Epoch 2/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1602 - acc: 0.8088 - val_loss: 0.1112 - val_acc: 0.8846\n",
      "Epoch 3/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1593 - acc: 0.8088 - val_loss: 0.1142 - val_acc: 0.8846\n",
      "Epoch 4/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1569 - acc: 0.8088 - val_loss: 0.1023 - val_acc: 0.8846\n",
      "Epoch 5/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1588 - acc: 0.8088 - val_loss: 0.1023 - val_acc: 0.8846\n",
      "Epoch 6/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1584 - acc: 0.8088 - val_loss: 0.1623 - val_acc: 0.8846\n",
      "Epoch 7/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1575 - acc: 0.8088 - val_loss: 0.1092 - val_acc: 0.8846\n",
      "Epoch 8/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1571 - acc: 0.8088 - val_loss: 0.1878 - val_acc: 0.8846\n",
      "Epoch 9/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1589 - acc: 0.8088 - val_loss: 0.1024 - val_acc: 0.8846\n",
      "Epoch 10/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1589 - acc: 0.8088 - val_loss: 0.1291 - val_acc: 0.8846\n",
      "Epoch 11/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1566 - acc: 0.8088 - val_loss: 0.1140 - val_acc: 0.8846\n",
      "Epoch 12/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1578 - acc: 0.8088 - val_loss: 0.1147 - val_acc: 0.8846\n",
      "Epoch 13/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1566 - acc: 0.8088 - val_loss: 0.1124 - val_acc: 0.8846\n",
      "Epoch 14/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1574 - acc: 0.8088 - val_loss: 0.1085 - val_acc: 0.8846\n",
      "Epoch 15/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1559 - acc: 0.8088 - val_loss: 0.1105 - val_acc: 0.8846\n",
      "Epoch 16/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1573 - acc: 0.8088 - val_loss: 0.1025 - val_acc: 0.8846\n",
      "Epoch 17/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1558 - acc: 0.8088 - val_loss: 0.1159 - val_acc: 0.8846\n",
      "Epoch 18/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1610 - acc: 0.8088 - val_loss: 0.1062 - val_acc: 0.8846\n",
      "Epoch 19/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1554 - acc: 0.8088 - val_loss: 0.1025 - val_acc: 0.8846\n",
      "Epoch 20/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1581 - acc: 0.8088 - val_loss: 0.1134 - val_acc: 0.8846\n",
      "Epoch 21/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1608 - acc: 0.8088 - val_loss: 0.1066 - val_acc: 0.8846\n",
      "Epoch 22/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1560 - acc: 0.8088 - val_loss: 0.1026 - val_acc: 0.8846\n",
      "Epoch 23/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1561 - acc: 0.8088 - val_loss: 0.1708 - val_acc: 0.8846\n",
      "Epoch 24/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1658 - acc: 0.8088 - val_loss: 0.1027 - val_acc: 0.8846\n",
      "Epoch 25/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1565 - acc: 0.8088 - val_loss: 0.1421 - val_acc: 0.8846\n",
      "Epoch 26/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1588 - acc: 0.8088 - val_loss: 0.1315 - val_acc: 0.8846\n",
      "Epoch 27/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1581 - acc: 0.8088 - val_loss: 0.1027 - val_acc: 0.8846\n",
      "Epoch 28/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1592 - acc: 0.8088 - val_loss: 0.1123 - val_acc: 0.8846\n",
      "Epoch 29/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1560 - acc: 0.8088 - val_loss: 0.1193 - val_acc: 0.8846\n",
      "Epoch 30/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1576 - acc: 0.8088 - val_loss: 0.1032 - val_acc: 0.8846\n",
      "Epoch 31/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1570 - acc: 0.8088 - val_loss: 0.1098 - val_acc: 0.8846\n",
      "Epoch 32/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1569 - acc: 0.8088 - val_loss: 0.1407 - val_acc: 0.8846\n",
      "Epoch 33/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1548 - acc: 0.8088 - val_loss: 0.1142 - val_acc: 0.8846\n",
      "Epoch 34/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1545 - acc: 0.8088 - val_loss: 0.1110 - val_acc: 0.8846\n",
      "Epoch 35/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1561 - acc: 0.8088 - val_loss: 0.1028 - val_acc: 0.8846\n",
      "Epoch 36/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1599 - acc: 0.8088 - val_loss: 0.1031 - val_acc: 0.8846\n",
      "Epoch 37/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1578 - acc: 0.8088 - val_loss: 0.1031 - val_acc: 0.8846\n",
      "Epoch 38/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1581 - acc: 0.8088 - val_loss: 0.1029 - val_acc: 0.8846\n",
      "Epoch 39/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1564 - acc: 0.8088 - val_loss: 0.1029 - val_acc: 0.8846\n",
      "Epoch 40/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1566 - acc: 0.8088 - val_loss: 0.1034 - val_acc: 0.8846\n",
      "Epoch 41/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1566 - acc: 0.8088 - val_loss: 0.1143 - val_acc: 0.8846\n",
      "Epoch 42/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1560 - acc: 0.8088 - val_loss: 0.1033 - val_acc: 0.8846\n",
      "Epoch 43/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1544 - acc: 0.8088 - val_loss: 0.1146 - val_acc: 0.8846\n",
      "Epoch 44/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1567 - acc: 0.8088 - val_loss: 0.1038 - val_acc: 0.8846\n",
      "Epoch 45/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1559 - acc: 0.8088 - val_loss: 0.1095 - val_acc: 0.8846\n",
      "Epoch 46/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1563 - acc: 0.8088 - val_loss: 0.1962 - val_acc: 0.8846\n",
      "Epoch 47/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1637 - acc: 0.8088 - val_loss: 0.1037 - val_acc: 0.8846\n",
      "Epoch 48/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1554 - acc: 0.8088 - val_loss: 0.1032 - val_acc: 0.8846\n",
      "Epoch 49/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1554 - acc: 0.8088 - val_loss: 0.1044 - val_acc: 0.8846\n",
      "Epoch 50/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1550 - acc: 0.8088 - val_loss: 0.1040 - val_acc: 0.8846\n",
      "Epoch 51/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1547 - acc: 0.8088 - val_loss: 0.1158 - val_acc: 0.8846\n",
      "Epoch 52/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1561 - acc: 0.8088 - val_loss: 0.1038 - val_acc: 0.8846\n",
      "Epoch 53/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1542 - acc: 0.8088 - val_loss: 0.1387 - val_acc: 0.8846\n",
      "Epoch 54/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1576 - acc: 0.8088 - val_loss: 0.1037 - val_acc: 0.8846\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.1560 - acc: 0.8088 - val_loss: 0.1037 - val_acc: 0.8846\n",
      "Epoch 56/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1556 - acc: 0.8088 - val_loss: 0.1035 - val_acc: 0.8846\n",
      "Epoch 57/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1560 - acc: 0.8088 - val_loss: 0.1035 - val_acc: 0.8846\n",
      "Epoch 58/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1561 - acc: 0.8088 - val_loss: 0.1035 - val_acc: 0.8846\n",
      "Epoch 59/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1550 - acc: 0.8088 - val_loss: 0.1339 - val_acc: 0.8846\n",
      "Epoch 60/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1568 - acc: 0.8088 - val_loss: 0.1041 - val_acc: 0.8846\n",
      "Epoch 61/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1562 - acc: 0.8088 - val_loss: 0.1102 - val_acc: 0.8846\n",
      "Epoch 62/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1552 - acc: 0.8088 - val_loss: 0.1093 - val_acc: 0.8846\n",
      "Epoch 63/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1547 - acc: 0.8088 - val_loss: 0.1051 - val_acc: 0.8846\n",
      "Epoch 64/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1548 - acc: 0.8088 - val_loss: 0.1045 - val_acc: 0.8846\n",
      "Epoch 65/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1547 - acc: 0.8088 - val_loss: 0.1046 - val_acc: 0.8846\n",
      "Epoch 66/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1547 - acc: 0.8088 - val_loss: 0.1127 - val_acc: 0.8846\n",
      "Epoch 67/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1555 - acc: 0.8088 - val_loss: 0.1820 - val_acc: 0.8846\n",
      "Epoch 68/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1667 - acc: 0.8088 - val_loss: 0.1158 - val_acc: 0.8846\n",
      "Epoch 69/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1533 - acc: 0.8088 - val_loss: 0.1115 - val_acc: 0.8846\n",
      "Epoch 70/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1543 - acc: 0.8088 - val_loss: 0.1216 - val_acc: 0.8846\n",
      "Epoch 71/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1543 - acc: 0.8088 - val_loss: 0.1099 - val_acc: 0.8846\n",
      "Epoch 72/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1534 - acc: 0.8088 - val_loss: 0.1978 - val_acc: 0.8846\n",
      "Epoch 73/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1603 - acc: 0.8088 - val_loss: 0.1051 - val_acc: 0.8846\n",
      "Epoch 74/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1546 - acc: 0.8088 - val_loss: 0.1051 - val_acc: 0.8846\n",
      "Epoch 75/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1542 - acc: 0.8088 - val_loss: 0.1055 - val_acc: 0.8846\n",
      "Epoch 76/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1541 - acc: 0.8088 - val_loss: 0.1223 - val_acc: 0.8846\n",
      "Epoch 77/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1566 - acc: 0.8088 - val_loss: 0.1239 - val_acc: 0.8846\n",
      "Epoch 78/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1536 - acc: 0.8088 - val_loss: 0.1051 - val_acc: 0.8846\n",
      "Epoch 79/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1541 - acc: 0.8088 - val_loss: 0.1062 - val_acc: 0.8846\n",
      "Epoch 80/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1537 - acc: 0.8088 - val_loss: 0.1180 - val_acc: 0.8846\n",
      "Epoch 81/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1530 - acc: 0.8088 - val_loss: 0.1159 - val_acc: 0.8846\n",
      "Epoch 82/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1526 - acc: 0.8088 - val_loss: 0.1114 - val_acc: 0.8846\n",
      "Epoch 83/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1544 - acc: 0.8088 - val_loss: 0.1056 - val_acc: 0.8846\n",
      "Epoch 84/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1530 - acc: 0.8088 - val_loss: 0.1141 - val_acc: 0.8846\n",
      "Epoch 85/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1558 - acc: 0.8088 - val_loss: 0.1050 - val_acc: 0.8846\n",
      "Epoch 86/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1536 - acc: 0.8088 - val_loss: 0.1055 - val_acc: 0.8846\n",
      "Epoch 87/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1544 - acc: 0.8088 - val_loss: 0.1056 - val_acc: 0.8846\n",
      "Epoch 88/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1542 - acc: 0.8088 - val_loss: 0.1058 - val_acc: 0.8846\n",
      "Epoch 89/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1532 - acc: 0.8088 - val_loss: 0.1058 - val_acc: 0.8846\n",
      "Epoch 90/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1544 - acc: 0.8088 - val_loss: 0.1114 - val_acc: 0.8846\n",
      "Epoch 91/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1510 - acc: 0.8088 - val_loss: 0.1547 - val_acc: 0.8846\n",
      "Epoch 92/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1558 - acc: 0.8088 - val_loss: 0.1103 - val_acc: 0.8846\n",
      "Epoch 93/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1521 - acc: 0.8088 - val_loss: 0.1056 - val_acc: 0.8846\n",
      "Epoch 94/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1556 - acc: 0.8088 - val_loss: 0.1101 - val_acc: 0.8846\n",
      "Epoch 95/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1525 - acc: 0.8088 - val_loss: 0.1151 - val_acc: 0.8846\n",
      "Epoch 96/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1535 - acc: 0.8088 - val_loss: 0.1176 - val_acc: 0.8846\n",
      "Epoch 97/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1514 - acc: 0.8088 - val_loss: 0.1289 - val_acc: 0.8846\n",
      "Epoch 98/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1547 - acc: 0.8088 - val_loss: 0.1128 - val_acc: 0.8846\n",
      "Epoch 99/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1535 - acc: 0.8088 - val_loss: 0.1332 - val_acc: 0.8846\n",
      "Epoch 100/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1522 - acc: 0.8088 - val_loss: 0.1092 - val_acc: 0.8846\n",
      "Epoch 101/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1520 - acc: 0.8088 - val_loss: 0.1151 - val_acc: 0.8846\n",
      "Epoch 102/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1515 - acc: 0.8088 - val_loss: 0.1080 - val_acc: 0.8846\n",
      "Epoch 103/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1522 - acc: 0.8088 - val_loss: 0.1072 - val_acc: 0.8846\n",
      "Epoch 104/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1545 - acc: 0.8088 - val_loss: 0.1083 - val_acc: 0.8846\n",
      "Epoch 105/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1515 - acc: 0.8088 - val_loss: 0.1172 - val_acc: 0.8846\n",
      "Epoch 106/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1526 - acc: 0.8088 - val_loss: 0.1082 - val_acc: 0.8846\n",
      "Epoch 107/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1518 - acc: 0.8088 - val_loss: 0.1092 - val_acc: 0.8846\n",
      "Epoch 108/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1498 - acc: 0.8088 - val_loss: 0.1130 - val_acc: 0.8846\n",
      "Epoch 109/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1505 - acc: 0.8088 - val_loss: 0.1210 - val_acc: 0.8846\n",
      "Epoch 110/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1513 - acc: 0.8088 - val_loss: 0.1123 - val_acc: 0.8846\n",
      "Epoch 111/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1515 - acc: 0.8088 - val_loss: 0.1096 - val_acc: 0.8846\n",
      "Epoch 112/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1505 - acc: 0.8088 - val_loss: 0.1252 - val_acc: 0.8846\n",
      "Epoch 113/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1492 - acc: 0.8088 - val_loss: 0.1077 - val_acc: 0.8846\n",
      "Epoch 114/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1518 - acc: 0.8088 - val_loss: 0.1096 - val_acc: 0.8846\n",
      "Epoch 115/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1498 - acc: 0.8088 - val_loss: 0.2056 - val_acc: 0.7115\n",
      "Epoch 116/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1532 - acc: 0.8039 - val_loss: 0.1180 - val_acc: 0.8846\n",
      "Epoch 117/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1506 - acc: 0.8088 - val_loss: 0.1101 - val_acc: 0.8846\n",
      "Epoch 118/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1486 - acc: 0.8088 - val_loss: 0.1136 - val_acc: 0.8846\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.1512 - acc: 0.8088 - val_loss: 0.1094 - val_acc: 0.8846\n",
      "Epoch 120/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1501 - acc: 0.8088 - val_loss: 0.1102 - val_acc: 0.8846\n",
      "Epoch 121/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1497 - acc: 0.8088 - val_loss: 0.1193 - val_acc: 0.8846\n",
      "Epoch 122/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1485 - acc: 0.8088 - val_loss: 0.1342 - val_acc: 0.8846\n",
      "Epoch 123/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1506 - acc: 0.8088 - val_loss: 0.1193 - val_acc: 0.8846\n",
      "Epoch 124/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1488 - acc: 0.8088 - val_loss: 0.1307 - val_acc: 0.8846\n",
      "Epoch 125/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1486 - acc: 0.8088 - val_loss: 0.1090 - val_acc: 0.8846\n",
      "Epoch 126/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1490 - acc: 0.8088 - val_loss: 0.1094 - val_acc: 0.8846\n",
      "Epoch 127/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1493 - acc: 0.8088 - val_loss: 0.1203 - val_acc: 0.8846\n",
      "Epoch 128/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1472 - acc: 0.8088 - val_loss: 0.1225 - val_acc: 0.8846\n",
      "Epoch 129/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1472 - acc: 0.8088 - val_loss: 0.1100 - val_acc: 0.8846\n",
      "Epoch 130/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1502 - acc: 0.8088 - val_loss: 0.1090 - val_acc: 0.8846\n",
      "Epoch 131/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1483 - acc: 0.8088 - val_loss: 0.1174 - val_acc: 0.8846\n",
      "Epoch 132/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1493 - acc: 0.8088 - val_loss: 0.1220 - val_acc: 0.8846\n",
      "Epoch 133/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1475 - acc: 0.8088 - val_loss: 0.1846 - val_acc: 0.8077\n",
      "Epoch 134/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1482 - acc: 0.8088 - val_loss: 0.1116 - val_acc: 0.8846\n",
      "Epoch 135/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1477 - acc: 0.8088 - val_loss: 0.1167 - val_acc: 0.8846\n",
      "Epoch 136/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1464 - acc: 0.8088 - val_loss: 0.1088 - val_acc: 0.8846\n",
      "Epoch 137/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1455 - acc: 0.8088 - val_loss: 0.1093 - val_acc: 0.8846\n",
      "Epoch 138/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1472 - acc: 0.8088 - val_loss: 0.1177 - val_acc: 0.8846\n",
      "Epoch 139/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1442 - acc: 0.8088 - val_loss: 0.1490 - val_acc: 0.8846\n",
      "Epoch 140/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1453 - acc: 0.8088 - val_loss: 0.1308 - val_acc: 0.8846\n",
      "Epoch 141/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1438 - acc: 0.8088 - val_loss: 0.1115 - val_acc: 0.8846\n",
      "Epoch 142/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1472 - acc: 0.8088 - val_loss: 0.1372 - val_acc: 0.8846\n",
      "Epoch 143/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1422 - acc: 0.8088 - val_loss: 0.1091 - val_acc: 0.8846\n",
      "Epoch 144/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1442 - acc: 0.8088 - val_loss: 0.1435 - val_acc: 0.8846\n",
      "Epoch 145/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1411 - acc: 0.8088 - val_loss: 0.1773 - val_acc: 0.8269\n",
      "Epoch 146/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1450 - acc: 0.8039 - val_loss: 0.1101 - val_acc: 0.8846\n",
      "Epoch 147/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1415 - acc: 0.8137 - val_loss: 0.1100 - val_acc: 0.8846\n",
      "Epoch 148/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1405 - acc: 0.8039 - val_loss: 0.1246 - val_acc: 0.8846\n",
      "Epoch 149/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1417 - acc: 0.8137 - val_loss: 0.1082 - val_acc: 0.8846\n",
      "Epoch 150/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1452 - acc: 0.8088 - val_loss: 0.1290 - val_acc: 0.8846\n",
      "Epoch 151/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1384 - acc: 0.8235 - val_loss: 0.1091 - val_acc: 0.8846\n",
      "Epoch 152/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1418 - acc: 0.8039 - val_loss: 0.1160 - val_acc: 0.8846\n",
      "Epoch 153/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1380 - acc: 0.8137 - val_loss: 0.1111 - val_acc: 0.8846\n",
      "Epoch 154/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1400 - acc: 0.8039 - val_loss: 0.1092 - val_acc: 0.8846\n",
      "Epoch 155/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1360 - acc: 0.8137 - val_loss: 0.1169 - val_acc: 0.8846\n",
      "Epoch 156/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1393 - acc: 0.8137 - val_loss: 0.2649 - val_acc: 0.5192\n",
      "Epoch 157/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1435 - acc: 0.8137 - val_loss: 0.1173 - val_acc: 0.8846\n",
      "Epoch 158/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1315 - acc: 0.8235 - val_loss: 0.1565 - val_acc: 0.8846\n",
      "Epoch 159/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1353 - acc: 0.8088 - val_loss: 0.1098 - val_acc: 0.8846\n",
      "Epoch 160/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1354 - acc: 0.8039 - val_loss: 0.1169 - val_acc: 0.8846\n",
      "Epoch 161/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1332 - acc: 0.8088 - val_loss: 0.1083 - val_acc: 0.8846\n",
      "Epoch 162/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1285 - acc: 0.8186 - val_loss: 0.3362 - val_acc: 0.2885\n",
      "Epoch 163/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1507 - acc: 0.7696 - val_loss: 0.1092 - val_acc: 0.8846\n",
      "Epoch 164/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1279 - acc: 0.8039 - val_loss: 0.1143 - val_acc: 0.8846\n",
      "Epoch 165/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1267 - acc: 0.8186 - val_loss: 0.1428 - val_acc: 0.8846\n",
      "Epoch 166/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1254 - acc: 0.8235 - val_loss: 0.1081 - val_acc: 0.8846\n",
      "Epoch 167/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1257 - acc: 0.8235 - val_loss: 0.1444 - val_acc: 0.8846\n",
      "Epoch 168/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1242 - acc: 0.8284 - val_loss: 0.1322 - val_acc: 0.8846\n",
      "Epoch 169/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1132 - acc: 0.8431 - val_loss: 0.1411 - val_acc: 0.8846\n",
      "Epoch 170/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1169 - acc: 0.8431 - val_loss: 0.1164 - val_acc: 0.8846\n",
      "Epoch 171/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1160 - acc: 0.8431 - val_loss: 0.1547 - val_acc: 0.8269\n",
      "Epoch 172/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1092 - acc: 0.8578 - val_loss: 0.1329 - val_acc: 0.8654\n",
      "Epoch 173/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1180 - acc: 0.8431 - val_loss: 0.1231 - val_acc: 0.8846\n",
      "Epoch 174/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1129 - acc: 0.8431 - val_loss: 0.1091 - val_acc: 0.8846\n",
      "Epoch 175/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1076 - acc: 0.8382 - val_loss: 0.1113 - val_acc: 0.8846\n",
      "Epoch 176/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1098 - acc: 0.8382 - val_loss: 0.1544 - val_acc: 0.7885\n",
      "Epoch 177/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0975 - acc: 0.8824 - val_loss: 0.1103 - val_acc: 0.8846\n",
      "Epoch 178/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1014 - acc: 0.8775 - val_loss: 0.1103 - val_acc: 0.8846\n",
      "Epoch 179/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0944 - acc: 0.8627 - val_loss: 0.1491 - val_acc: 0.8269\n",
      "Epoch 180/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0974 - acc: 0.8824 - val_loss: 0.1584 - val_acc: 0.8077\n",
      "Epoch 181/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0915 - acc: 0.8922 - val_loss: 0.1130 - val_acc: 0.8846\n",
      "Epoch 182/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1188 - acc: 0.8578 - val_loss: 0.1146 - val_acc: 0.8654\n",
      "Epoch 183/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0919 - acc: 0.8578 - val_loss: 0.1256 - val_acc: 0.8654\n",
      "Epoch 184/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0860 - acc: 0.9069 - val_loss: 0.1121 - val_acc: 0.8846\n",
      "Epoch 185/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0968 - acc: 0.8775 - val_loss: 0.1188 - val_acc: 0.8654\n",
      "Epoch 186/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0870 - acc: 0.8824 - val_loss: 0.2277 - val_acc: 0.6346\n",
      "Epoch 187/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0851 - acc: 0.9118 - val_loss: 0.1387 - val_acc: 0.8462\n",
      "Epoch 188/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0740 - acc: 0.9167 - val_loss: 0.1407 - val_acc: 0.8269\n",
      "Epoch 189/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0756 - acc: 0.9118 - val_loss: 0.1409 - val_acc: 0.8269\n",
      "Epoch 190/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0686 - acc: 0.9216 - val_loss: 0.1200 - val_acc: 0.8846\n",
      "Epoch 191/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0646 - acc: 0.9314 - val_loss: 0.1541 - val_acc: 0.8077\n",
      "Epoch 192/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0693 - acc: 0.9069 - val_loss: 0.1177 - val_acc: 0.8846\n",
      "Epoch 193/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0856 - acc: 0.9020 - val_loss: 0.1240 - val_acc: 0.8654\n",
      "Epoch 194/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0730 - acc: 0.9167 - val_loss: 0.1355 - val_acc: 0.8462\n",
      "Epoch 195/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0781 - acc: 0.8971 - val_loss: 0.2169 - val_acc: 0.7115\n",
      "Epoch 196/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0686 - acc: 0.9216 - val_loss: 0.1439 - val_acc: 0.8269\n",
      "Epoch 197/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0618 - acc: 0.9363 - val_loss: 0.1274 - val_acc: 0.8462\n",
      "Epoch 198/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0604 - acc: 0.9314 - val_loss: 0.2477 - val_acc: 0.6154\n",
      "Epoch 199/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0827 - acc: 0.8922 - val_loss: 0.1460 - val_acc: 0.8269\n",
      "Epoch 200/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0551 - acc: 0.9461 - val_loss: 0.1798 - val_acc: 0.7115\n",
      "Epoch 201/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0555 - acc: 0.9461 - val_loss: 0.1236 - val_acc: 0.8654\n",
      "Epoch 202/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0602 - acc: 0.9314 - val_loss: 0.1581 - val_acc: 0.8077\n",
      "Epoch 203/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0589 - acc: 0.9265 - val_loss: 0.2195 - val_acc: 0.6923\n",
      "Epoch 204/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0623 - acc: 0.9412 - val_loss: 0.1352 - val_acc: 0.8269\n",
      "Epoch 205/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0445 - acc: 0.9608 - val_loss: 0.1372 - val_acc: 0.8462\n",
      "Epoch 206/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0568 - acc: 0.9363 - val_loss: 0.1479 - val_acc: 0.8269\n",
      "Epoch 207/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0442 - acc: 0.9559 - val_loss: 0.1523 - val_acc: 0.8269\n",
      "Epoch 208/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0415 - acc: 0.9510 - val_loss: 0.1521 - val_acc: 0.8269\n",
      "Epoch 209/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0422 - acc: 0.9559 - val_loss: 0.1413 - val_acc: 0.8269\n",
      "Epoch 210/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0422 - acc: 0.9510 - val_loss: 0.1392 - val_acc: 0.8462\n",
      "Epoch 211/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0443 - acc: 0.9559 - val_loss: 0.1274 - val_acc: 0.8462\n",
      "Epoch 212/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0598 - acc: 0.9265 - val_loss: 0.4497 - val_acc: 0.3462\n",
      "Epoch 213/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1019 - acc: 0.8725 - val_loss: 0.4789 - val_acc: 0.3654\n",
      "Epoch 214/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0668 - acc: 0.9167 - val_loss: 0.1483 - val_acc: 0.8269\n",
      "Epoch 215/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0376 - acc: 0.9657 - val_loss: 0.1571 - val_acc: 0.7885\n",
      "Epoch 216/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0336 - acc: 0.9657 - val_loss: 0.1487 - val_acc: 0.8077\n",
      "Epoch 217/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0332 - acc: 0.9706 - val_loss: 0.1417 - val_acc: 0.8269\n",
      "Epoch 218/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0359 - acc: 0.9608 - val_loss: 0.1526 - val_acc: 0.8077\n",
      "Epoch 219/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0317 - acc: 0.9706 - val_loss: 0.1430 - val_acc: 0.8269\n",
      "Epoch 220/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0320 - acc: 0.9706 - val_loss: 0.1520 - val_acc: 0.8077\n",
      "Epoch 221/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0323 - acc: 0.9706 - val_loss: 0.1570 - val_acc: 0.8077\n",
      "Epoch 222/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0301 - acc: 0.9706 - val_loss: 0.1676 - val_acc: 0.8077\n",
      "Epoch 223/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0304 - acc: 0.9706 - val_loss: 0.1541 - val_acc: 0.8077\n",
      "Epoch 224/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0297 - acc: 0.9706 - val_loss: 0.2156 - val_acc: 0.7115\n",
      "Epoch 225/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0493 - acc: 0.9461 - val_loss: 0.1710 - val_acc: 0.8077\n",
      "Epoch 226/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0295 - acc: 0.9706 - val_loss: 0.1607 - val_acc: 0.8077\n",
      "Epoch 227/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0291 - acc: 0.9706 - val_loss: 0.1745 - val_acc: 0.7885\n",
      "Epoch 228/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0283 - acc: 0.9706 - val_loss: 0.1598 - val_acc: 0.8077\n",
      "Epoch 229/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0287 - acc: 0.9657 - val_loss: 0.1638 - val_acc: 0.8077\n",
      "Epoch 230/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0294 - acc: 0.9755 - val_loss: 0.1668 - val_acc: 0.8077\n",
      "Epoch 231/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0271 - acc: 0.9755 - val_loss: 0.1711 - val_acc: 0.8077\n",
      "Epoch 232/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0292 - acc: 0.9706 - val_loss: 0.1872 - val_acc: 0.7500\n",
      "Epoch 233/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0321 - acc: 0.9657 - val_loss: 0.1860 - val_acc: 0.7885\n",
      "Epoch 234/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0276 - acc: 0.9706 - val_loss: 0.1645 - val_acc: 0.8077\n",
      "Epoch 235/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0289 - acc: 0.9657 - val_loss: 0.1820 - val_acc: 0.7692\n",
      "Epoch 236/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0315 - acc: 0.9608 - val_loss: 0.1625 - val_acc: 0.8077\n",
      "Epoch 237/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0244 - acc: 0.9755 - val_loss: 0.1738 - val_acc: 0.8077\n",
      "Epoch 238/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0255 - acc: 0.9755 - val_loss: 0.1881 - val_acc: 0.7692\n",
      "Epoch 239/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0281 - acc: 0.9755 - val_loss: 0.1477 - val_acc: 0.8269\n",
      "Epoch 240/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0320 - acc: 0.9706 - val_loss: 0.1771 - val_acc: 0.7885\n",
      "Epoch 241/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0311 - acc: 0.9608 - val_loss: 0.1646 - val_acc: 0.8077\n",
      "Epoch 242/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0223 - acc: 0.9755 - val_loss: 0.1794 - val_acc: 0.8077\n",
      "Epoch 243/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0230 - acc: 0.9804 - val_loss: 0.1702 - val_acc: 0.8077\n",
      "Epoch 244/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0216 - acc: 0.9804 - val_loss: 0.1741 - val_acc: 0.8077\n",
      "Epoch 245/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0228 - acc: 0.9755 - val_loss: 0.1616 - val_acc: 0.8077\n",
      "Epoch 246/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0254 - acc: 0.9706 - val_loss: 0.1631 - val_acc: 0.8269\n",
      "Epoch 247/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0210 - acc: 0.9804 - val_loss: 0.1652 - val_acc: 0.8077\n",
      "Epoch 248/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0220 - acc: 0.9804 - val_loss: 0.1649 - val_acc: 0.8077\n",
      "Epoch 249/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0204 - acc: 0.9804 - val_loss: 0.1651 - val_acc: 0.8077\n",
      "Epoch 250/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0220 - acc: 0.9804 - val_loss: 0.1672 - val_acc: 0.8077\n",
      "Epoch 251/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0211 - acc: 0.9804 - val_loss: 0.1599 - val_acc: 0.8077\n",
      "Epoch 252/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0246 - acc: 0.9755 - val_loss: 0.1592 - val_acc: 0.8077\n",
      "Epoch 253/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0249 - acc: 0.9706 - val_loss: 0.1160 - val_acc: 0.8462\n",
      "Epoch 254/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1561 - acc: 0.8186 - val_loss: 0.1182 - val_acc: 0.8846\n",
      "Epoch 255/1000\n",
      "204/204 [==============================] - 0s - loss: 0.1164 - acc: 0.8775 - val_loss: 0.1191 - val_acc: 0.8846\n",
      "Epoch 256/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0912 - acc: 0.9069 - val_loss: 0.1467 - val_acc: 0.8462\n",
      "Epoch 257/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0828 - acc: 0.9118 - val_loss: 0.1348 - val_acc: 0.8654\n",
      "Epoch 258/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0701 - acc: 0.9265 - val_loss: 0.1834 - val_acc: 0.7692\n",
      "Epoch 259/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0495 - acc: 0.9461 - val_loss: 0.1914 - val_acc: 0.7692\n",
      "Epoch 260/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0452 - acc: 0.9559 - val_loss: 0.1843 - val_acc: 0.7885\n",
      "Epoch 261/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0374 - acc: 0.9657 - val_loss: 0.1911 - val_acc: 0.7885\n",
      "Epoch 262/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0383 - acc: 0.9559 - val_loss: 0.1952 - val_acc: 0.7692\n",
      "Epoch 263/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0270 - acc: 0.9755 - val_loss: 0.1884 - val_acc: 0.7885\n",
      "Epoch 264/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0260 - acc: 0.9755 - val_loss: 0.1811 - val_acc: 0.7885\n",
      "Epoch 265/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0253 - acc: 0.9755 - val_loss: 0.1892 - val_acc: 0.7692\n",
      "Epoch 266/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0322 - acc: 0.9657 - val_loss: 0.1932 - val_acc: 0.7692\n",
      "Epoch 267/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0259 - acc: 0.9755 - val_loss: 0.1806 - val_acc: 0.7885\n",
      "Epoch 268/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0399 - acc: 0.9608 - val_loss: 0.1703 - val_acc: 0.7885\n",
      "Epoch 269/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0267 - acc: 0.9706 - val_loss: 0.1747 - val_acc: 0.7885\n",
      "Epoch 270/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0290 - acc: 0.9706 - val_loss: 0.1688 - val_acc: 0.7885\n",
      "Epoch 271/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0273 - acc: 0.9706 - val_loss: 0.1737 - val_acc: 0.7885\n",
      "Epoch 272/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0271 - acc: 0.9657 - val_loss: 0.1706 - val_acc: 0.8077\n",
      "Epoch 273/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0397 - acc: 0.9510 - val_loss: 0.1865 - val_acc: 0.7885\n",
      "Epoch 274/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0312 - acc: 0.9608 - val_loss: 0.3221 - val_acc: 0.5769\n",
      "Epoch 275/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0356 - acc: 0.9461 - val_loss: 0.1812 - val_acc: 0.7885\n",
      "Epoch 276/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0248 - acc: 0.9755 - val_loss: 0.2642 - val_acc: 0.6731\n",
      "Epoch 277/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0290 - acc: 0.9608 - val_loss: 0.1993 - val_acc: 0.7500\n",
      "Epoch 278/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0334 - acc: 0.9657 - val_loss: 0.1606 - val_acc: 0.8077\n",
      "Epoch 279/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0255 - acc: 0.9755 - val_loss: 0.2510 - val_acc: 0.6923\n",
      "Epoch 280/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0628 - acc: 0.9216 - val_loss: 0.1673 - val_acc: 0.8077\n",
      "Epoch 281/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0347 - acc: 0.9657 - val_loss: 0.1580 - val_acc: 0.8269\n",
      "Epoch 282/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0295 - acc: 0.9706 - val_loss: 0.1574 - val_acc: 0.8269\n",
      "Epoch 283/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0264 - acc: 0.9755 - val_loss: 0.1582 - val_acc: 0.8269\n",
      "Epoch 284/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0249 - acc: 0.9755 - val_loss: 0.1544 - val_acc: 0.8269\n",
      "Epoch 285/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0269 - acc: 0.9706 - val_loss: 0.1585 - val_acc: 0.8269\n",
      "Epoch 286/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0245 - acc: 0.9755 - val_loss: 0.1715 - val_acc: 0.8077\n",
      "Epoch 287/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0229 - acc: 0.9706 - val_loss: 0.1652 - val_acc: 0.8269\n",
      "Epoch 288/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0226 - acc: 0.9755 - val_loss: 0.1423 - val_acc: 0.8462\n",
      "Epoch 289/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0293 - acc: 0.9706 - val_loss: 0.1622 - val_acc: 0.8269\n",
      "Epoch 290/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0228 - acc: 0.9755 - val_loss: 0.1311 - val_acc: 0.8462\n",
      "Epoch 291/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0315 - acc: 0.9608 - val_loss: 0.1716 - val_acc: 0.8269\n",
      "Epoch 292/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0249 - acc: 0.9755 - val_loss: 0.1729 - val_acc: 0.8269\n",
      "Epoch 293/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0209 - acc: 0.9804 - val_loss: 0.2381 - val_acc: 0.7115\n",
      "Epoch 294/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0563 - acc: 0.9314 - val_loss: 0.1843 - val_acc: 0.7692\n",
      "Epoch 295/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0321 - acc: 0.9657 - val_loss: 0.1778 - val_acc: 0.7885\n",
      "Epoch 296/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0289 - acc: 0.9706 - val_loss: 0.1730 - val_acc: 0.8077\n",
      "Epoch 297/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0274 - acc: 0.9706 - val_loss: 0.1699 - val_acc: 0.8077\n",
      "Epoch 298/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0247 - acc: 0.9755 - val_loss: 0.1618 - val_acc: 0.8269\n",
      "Epoch 299/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0240 - acc: 0.9755 - val_loss: 0.1574 - val_acc: 0.8269\n",
      "Epoch 300/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0243 - acc: 0.9706 - val_loss: 0.1547 - val_acc: 0.8462\n",
      "Epoch 301/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0232 - acc: 0.9706 - val_loss: 0.1577 - val_acc: 0.8462\n",
      "Epoch 302/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0219 - acc: 0.9755 - val_loss: 0.1564 - val_acc: 0.8462\n",
      "Epoch 303/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0202 - acc: 0.9804 - val_loss: 0.1628 - val_acc: 0.8077\n",
      "Epoch 304/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0202 - acc: 0.9755 - val_loss: 0.1650 - val_acc: 0.8077\n",
      "Epoch 305/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0198 - acc: 0.9755 - val_loss: 0.1628 - val_acc: 0.8077\n",
      "Epoch 306/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0200 - acc: 0.9804 - val_loss: 0.1663 - val_acc: 0.8077\n",
      "Epoch 307/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0198 - acc: 0.9755 - val_loss: 0.3100 - val_acc: 0.5962\n",
      "Epoch 308/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0300 - acc: 0.9706 - val_loss: 0.1784 - val_acc: 0.7885\n",
      "Epoch 309/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0294 - acc: 0.9608 - val_loss: 0.1841 - val_acc: 0.7692\n",
      "Epoch 310/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0214 - acc: 0.9804 - val_loss: 0.1656 - val_acc: 0.7885\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0163 - acc: 0.9755 - val_loss: 0.1711 - val_acc: 0.7885\n",
      "Epoch 312/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0174 - acc: 0.9755 - val_loss: 0.1732 - val_acc: 0.7885\n",
      "Epoch 313/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0202 - acc: 0.9755 - val_loss: 0.1764 - val_acc: 0.7500\n",
      "Epoch 314/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0183 - acc: 0.9853 - val_loss: 0.1693 - val_acc: 0.7885\n",
      "Epoch 315/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1692 - val_acc: 0.7885\n",
      "Epoch 316/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0155 - acc: 0.9804 - val_loss: 0.1281 - val_acc: 0.8654\n",
      "Epoch 317/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0296 - acc: 0.9706 - val_loss: 0.1647 - val_acc: 0.8077\n",
      "Epoch 318/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1598 - val_acc: 0.8077\n",
      "Epoch 319/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0163 - acc: 0.9853 - val_loss: 0.1606 - val_acc: 0.8077\n",
      "Epoch 320/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1730 - val_acc: 0.7885\n",
      "Epoch 321/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9804 - val_loss: 0.1697 - val_acc: 0.8077\n",
      "Epoch 322/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1447 - val_acc: 0.8654\n",
      "Epoch 323/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0156 - acc: 0.9853 - val_loss: 0.1727 - val_acc: 0.8077\n",
      "Epoch 324/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0128 - acc: 0.9853 - val_loss: 0.1616 - val_acc: 0.8077\n",
      "Epoch 325/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0126 - acc: 0.9853 - val_loss: 0.1793 - val_acc: 0.7692\n",
      "Epoch 326/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9853 - val_loss: 0.1793 - val_acc: 0.7500\n",
      "Epoch 327/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9853 - val_loss: 0.1691 - val_acc: 0.8077\n",
      "Epoch 328/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.1729 - val_acc: 0.7885\n",
      "Epoch 329/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1725 - val_acc: 0.8077\n",
      "Epoch 330/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1751 - val_acc: 0.7885\n",
      "Epoch 331/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0115 - acc: 0.9853 - val_loss: 0.1781 - val_acc: 0.7500\n",
      "Epoch 332/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9804 - val_loss: 0.1768 - val_acc: 0.7692\n",
      "Epoch 333/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0164 - acc: 0.9755 - val_loss: 0.1613 - val_acc: 0.8077\n",
      "Epoch 334/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1657 - val_acc: 0.8077\n",
      "Epoch 335/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1691 - val_acc: 0.7692\n",
      "Epoch 336/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0182 - acc: 0.9804 - val_loss: 0.1615 - val_acc: 0.8269\n",
      "Epoch 337/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0154 - acc: 0.9804 - val_loss: 0.1641 - val_acc: 0.8269\n",
      "Epoch 338/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0130 - acc: 0.9853 - val_loss: 0.1623 - val_acc: 0.8077\n",
      "Epoch 339/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1902 - val_acc: 0.7692\n",
      "Epoch 340/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0171 - acc: 0.9853 - val_loss: 0.1575 - val_acc: 0.8269\n",
      "Epoch 341/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0158 - acc: 0.9804 - val_loss: 0.3853 - val_acc: 0.5577\n",
      "Epoch 342/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0477 - acc: 0.9412 - val_loss: 0.1460 - val_acc: 0.8269\n",
      "Epoch 343/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0236 - acc: 0.9706 - val_loss: 0.1708 - val_acc: 0.8077\n",
      "Epoch 344/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1644 - val_acc: 0.7885\n",
      "Epoch 345/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0155 - acc: 0.9804 - val_loss: 0.1588 - val_acc: 0.7885\n",
      "Epoch 346/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0176 - acc: 0.9804 - val_loss: 0.1555 - val_acc: 0.8269\n",
      "Epoch 347/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0128 - acc: 0.9853 - val_loss: 0.1526 - val_acc: 0.8269\n",
      "Epoch 348/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0157 - acc: 0.9755 - val_loss: 0.1493 - val_acc: 0.8269\n",
      "Epoch 349/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0104 - acc: 0.9902 - val_loss: 0.1624 - val_acc: 0.7885\n",
      "Epoch 350/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0167 - acc: 0.9804 - val_loss: 0.1509 - val_acc: 0.8269\n",
      "Epoch 351/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0103 - acc: 0.9902 - val_loss: 0.1545 - val_acc: 0.8077\n",
      "Epoch 352/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0121 - acc: 0.9853 - val_loss: 0.1555 - val_acc: 0.8269\n",
      "Epoch 353/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9853 - val_loss: 0.1595 - val_acc: 0.8077\n",
      "Epoch 354/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0189 - acc: 0.9706 - val_loss: 0.1545 - val_acc: 0.8269\n",
      "Epoch 355/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1565 - val_acc: 0.8269\n",
      "Epoch 356/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0106 - acc: 0.9853 - val_loss: 0.1517 - val_acc: 0.8269\n",
      "Epoch 357/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0105 - acc: 0.9902 - val_loss: 0.1566 - val_acc: 0.7885\n",
      "Epoch 358/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9804 - val_loss: 0.1514 - val_acc: 0.8269\n",
      "Epoch 359/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.1563 - val_acc: 0.8269\n",
      "Epoch 360/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1547 - val_acc: 0.8269\n",
      "Epoch 361/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0108 - acc: 0.9853 - val_loss: 0.1755 - val_acc: 0.7885\n",
      "Epoch 362/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1558 - val_acc: 0.8269\n",
      "Epoch 363/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0111 - acc: 0.9902 - val_loss: 0.1375 - val_acc: 0.8654\n",
      "Epoch 364/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0195 - acc: 0.9706 - val_loss: 0.1543 - val_acc: 0.8077\n",
      "Epoch 365/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0127 - acc: 0.9853 - val_loss: 0.1576 - val_acc: 0.8077\n",
      "Epoch 366/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1525 - val_acc: 0.8269\n",
      "Epoch 367/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0128 - acc: 0.9902 - val_loss: 0.1519 - val_acc: 0.8269\n",
      "Epoch 368/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0156 - acc: 0.9804 - val_loss: 0.1576 - val_acc: 0.8269\n",
      "Epoch 369/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0155 - acc: 0.9804 - val_loss: 0.1616 - val_acc: 0.8269\n",
      "Epoch 370/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0106 - acc: 0.9902 - val_loss: 0.1668 - val_acc: 0.8077\n",
      "Epoch 371/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0125 - acc: 0.9853 - val_loss: 0.1601 - val_acc: 0.8269\n",
      "Epoch 372/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0092 - acc: 0.9853 - val_loss: 0.1990 - val_acc: 0.7500\n",
      "Epoch 373/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0205 - acc: 0.9657 - val_loss: 0.1831 - val_acc: 0.7885\n",
      "Epoch 374/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9804 - val_loss: 0.1709 - val_acc: 0.8077\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0157 - acc: 0.9755 - val_loss: 0.1773 - val_acc: 0.7692\n",
      "Epoch 376/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0149 - acc: 0.9804 - val_loss: 0.1645 - val_acc: 0.8269\n",
      "Epoch 377/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1637 - val_acc: 0.8077\n",
      "Epoch 378/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0112 - acc: 0.9853 - val_loss: 0.1933 - val_acc: 0.7308\n",
      "Epoch 379/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0169 - acc: 0.9755 - val_loss: 0.1773 - val_acc: 0.7692\n",
      "Epoch 380/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1615 - val_acc: 0.8269\n",
      "Epoch 381/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9755 - val_loss: 0.1645 - val_acc: 0.8269\n",
      "Epoch 382/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0113 - acc: 0.9804 - val_loss: 0.1652 - val_acc: 0.8077\n",
      "Epoch 383/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0108 - acc: 0.9902 - val_loss: 0.1615 - val_acc: 0.8269\n",
      "Epoch 384/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0109 - acc: 0.9853 - val_loss: 0.1654 - val_acc: 0.8269\n",
      "Epoch 385/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1630 - val_acc: 0.8269\n",
      "Epoch 386/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1612 - val_acc: 0.8077\n",
      "Epoch 387/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1613 - val_acc: 0.8269\n",
      "Epoch 388/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0093 - acc: 0.9902 - val_loss: 0.1761 - val_acc: 0.7500\n",
      "Epoch 389/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0107 - acc: 0.9853 - val_loss: 0.1568 - val_acc: 0.8269\n",
      "Epoch 390/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0149 - acc: 0.9804 - val_loss: 0.1491 - val_acc: 0.8462\n",
      "Epoch 391/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0127 - acc: 0.9853 - val_loss: 0.1880 - val_acc: 0.7308\n",
      "Epoch 392/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1536 - val_acc: 0.8269\n",
      "Epoch 393/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9804 - val_loss: 0.1554 - val_acc: 0.8269\n",
      "Epoch 394/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0126 - acc: 0.9853 - val_loss: 0.1701 - val_acc: 0.7692\n",
      "Epoch 395/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0105 - acc: 0.9902 - val_loss: 0.1571 - val_acc: 0.8269\n",
      "Epoch 396/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0124 - acc: 0.9853 - val_loss: 0.1683 - val_acc: 0.7692\n",
      "Epoch 397/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1724 - val_acc: 0.7692\n",
      "Epoch 398/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0121 - acc: 0.9804 - val_loss: 0.1956 - val_acc: 0.7500\n",
      "Epoch 399/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0164 - acc: 0.9755 - val_loss: 0.1617 - val_acc: 0.8269\n",
      "Epoch 400/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1611 - val_acc: 0.7692\n",
      "Epoch 401/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0162 - acc: 0.9755 - val_loss: 0.1543 - val_acc: 0.8269\n",
      "Epoch 402/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.1288 - val_acc: 0.8654\n",
      "Epoch 403/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0504 - acc: 0.9412 - val_loss: 0.1710 - val_acc: 0.7885\n",
      "Epoch 404/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0229 - acc: 0.9706 - val_loss: 0.1575 - val_acc: 0.8077\n",
      "Epoch 405/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9853 - val_loss: 0.1556 - val_acc: 0.8269\n",
      "Epoch 406/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1606 - val_acc: 0.8077\n",
      "Epoch 407/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1607 - val_acc: 0.8077\n",
      "Epoch 408/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1623 - val_acc: 0.8077\n",
      "Epoch 409/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1604 - val_acc: 0.8077\n",
      "Epoch 410/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1631 - val_acc: 0.8077\n",
      "Epoch 411/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1648 - val_acc: 0.8077\n",
      "Epoch 412/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0124 - acc: 0.9853 - val_loss: 0.1918 - val_acc: 0.7308\n",
      "Epoch 413/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9804 - val_loss: 0.1679 - val_acc: 0.8077\n",
      "Epoch 414/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0102 - acc: 0.9902 - val_loss: 0.1771 - val_acc: 0.7692\n",
      "Epoch 415/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0188 - acc: 0.9706 - val_loss: 0.1618 - val_acc: 0.8077\n",
      "Epoch 416/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0116 - acc: 0.9804 - val_loss: 0.1685 - val_acc: 0.8077\n",
      "Epoch 417/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9804 - val_loss: 0.1627 - val_acc: 0.8077\n",
      "Epoch 418/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9804 - val_loss: 0.1639 - val_acc: 0.8077\n",
      "Epoch 419/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0125 - acc: 0.9853 - val_loss: 0.1738 - val_acc: 0.7885\n",
      "Epoch 420/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1536 - val_acc: 0.8462\n",
      "Epoch 421/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0155 - acc: 0.9804 - val_loss: 0.1601 - val_acc: 0.8269\n",
      "Epoch 422/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1567 - val_acc: 0.8269\n",
      "Epoch 423/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1657 - val_acc: 0.8077\n",
      "Epoch 424/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1650 - val_acc: 0.8077\n",
      "Epoch 425/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1652 - val_acc: 0.8077\n",
      "Epoch 426/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1603 - val_acc: 0.8269\n",
      "Epoch 427/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1593 - val_acc: 0.8269\n",
      "Epoch 428/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0127 - acc: 0.9853 - val_loss: 0.1753 - val_acc: 0.8077\n",
      "Epoch 429/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1602 - val_acc: 0.8269\n",
      "Epoch 430/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0127 - acc: 0.9853 - val_loss: 0.1744 - val_acc: 0.8077\n",
      "Epoch 431/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0154 - acc: 0.9804 - val_loss: 0.1704 - val_acc: 0.8077\n",
      "Epoch 432/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1700 - val_acc: 0.8077\n",
      "Epoch 433/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1720 - val_acc: 0.8077\n",
      "Epoch 434/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0118 - acc: 0.9853 - val_loss: 0.1602 - val_acc: 0.8269\n",
      "Epoch 435/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0130 - acc: 0.9853 - val_loss: 0.1702 - val_acc: 0.8077\n",
      "Epoch 436/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0112 - acc: 0.9902 - val_loss: 0.1580 - val_acc: 0.8269\n",
      "Epoch 437/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0149 - acc: 0.9804 - val_loss: 0.1610 - val_acc: 0.8269\n",
      "Epoch 438/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9804 - val_loss: 0.1586 - val_acc: 0.8269\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0099 - acc: 0.9853 - val_loss: 0.1910 - val_acc: 0.7885\n",
      "Epoch 440/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9804 - val_loss: 0.1573 - val_acc: 0.8269\n",
      "Epoch 441/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0125 - acc: 0.9853 - val_loss: 0.1607 - val_acc: 0.8269\n",
      "Epoch 442/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0130 - acc: 0.9853 - val_loss: 0.1539 - val_acc: 0.8269\n",
      "Epoch 443/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0161 - acc: 0.9755 - val_loss: 0.1508 - val_acc: 0.8269\n",
      "Epoch 444/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9804 - val_loss: 0.1541 - val_acc: 0.8269\n",
      "Epoch 445/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9804 - val_loss: 0.1540 - val_acc: 0.8269\n",
      "Epoch 446/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0100 - acc: 0.9902 - val_loss: 0.1751 - val_acc: 0.7885\n",
      "Epoch 447/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9804 - val_loss: 0.1577 - val_acc: 0.8269\n",
      "Epoch 448/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1555 - val_acc: 0.8269\n",
      "Epoch 449/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0125 - acc: 0.9853 - val_loss: 0.1673 - val_acc: 0.7692\n",
      "Epoch 450/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0116 - acc: 0.9853 - val_loss: 0.1574 - val_acc: 0.8269\n",
      "Epoch 451/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1577 - val_acc: 0.8269\n",
      "Epoch 452/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0113 - acc: 0.9853 - val_loss: 0.1703 - val_acc: 0.7885\n",
      "Epoch 453/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9804 - val_loss: 0.1712 - val_acc: 0.7692\n",
      "Epoch 454/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9804 - val_loss: 0.1513 - val_acc: 0.8269\n",
      "Epoch 455/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0164 - acc: 0.9804 - val_loss: 0.1572 - val_acc: 0.8269\n",
      "Epoch 456/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9804 - val_loss: 0.1564 - val_acc: 0.8269\n",
      "Epoch 457/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1583 - val_acc: 0.8269\n",
      "Epoch 458/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9804 - val_loss: 0.1317 - val_acc: 0.8654\n",
      "Epoch 459/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0522 - acc: 0.9461 - val_loss: 0.1544 - val_acc: 0.8077\n",
      "Epoch 460/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0275 - acc: 0.9657 - val_loss: 0.1503 - val_acc: 0.8269\n",
      "Epoch 461/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0270 - acc: 0.9657 - val_loss: 0.1715 - val_acc: 0.8077\n",
      "Epoch 462/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0289 - acc: 0.9657 - val_loss: 0.1680 - val_acc: 0.8269\n",
      "Epoch 463/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9853 - val_loss: 0.1487 - val_acc: 0.8269\n",
      "Epoch 464/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0339 - acc: 0.9657 - val_loss: 0.1527 - val_acc: 0.8462\n",
      "Epoch 465/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0214 - acc: 0.9755 - val_loss: 0.1508 - val_acc: 0.8462\n",
      "Epoch 466/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0193 - acc: 0.9804 - val_loss: 0.1541 - val_acc: 0.8269\n",
      "Epoch 467/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0196 - acc: 0.9804 - val_loss: 0.1564 - val_acc: 0.8269\n",
      "Epoch 468/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0184 - acc: 0.9804 - val_loss: 0.1632 - val_acc: 0.7885\n",
      "Epoch 469/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0198 - acc: 0.9804 - val_loss: 0.1567 - val_acc: 0.8269\n",
      "Epoch 470/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0187 - acc: 0.9804 - val_loss: 0.1601 - val_acc: 0.7885\n",
      "Epoch 471/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0197 - acc: 0.9804 - val_loss: 0.1579 - val_acc: 0.8269\n",
      "Epoch 472/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0195 - acc: 0.9804 - val_loss: 0.1591 - val_acc: 0.8269\n",
      "Epoch 473/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0196 - acc: 0.9755 - val_loss: 0.1589 - val_acc: 0.8269\n",
      "Epoch 474/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0204 - acc: 0.9804 - val_loss: 0.1567 - val_acc: 0.8269\n",
      "Epoch 475/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0193 - acc: 0.9804 - val_loss: 0.1598 - val_acc: 0.8269\n",
      "Epoch 476/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0188 - acc: 0.9804 - val_loss: 0.1636 - val_acc: 0.8077\n",
      "Epoch 477/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0190 - acc: 0.9804 - val_loss: 0.1605 - val_acc: 0.8269\n",
      "Epoch 478/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0191 - acc: 0.9804 - val_loss: 0.1628 - val_acc: 0.8269\n",
      "Epoch 479/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0195 - acc: 0.9755 - val_loss: 0.1605 - val_acc: 0.8269\n",
      "Epoch 480/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0186 - acc: 0.9804 - val_loss: 0.1659 - val_acc: 0.8077\n",
      "Epoch 481/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0188 - acc: 0.9804 - val_loss: 0.1683 - val_acc: 0.7692\n",
      "Epoch 482/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0192 - acc: 0.9804 - val_loss: 0.1685 - val_acc: 0.7692\n",
      "Epoch 483/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0218 - acc: 0.9755 - val_loss: 0.1610 - val_acc: 0.8269\n",
      "Epoch 484/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0190 - acc: 0.9804 - val_loss: 0.1633 - val_acc: 0.8269\n",
      "Epoch 485/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0185 - acc: 0.9804 - val_loss: 0.1679 - val_acc: 0.7885\n",
      "Epoch 486/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0198 - acc: 0.9804 - val_loss: 0.1626 - val_acc: 0.8077\n",
      "Epoch 487/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0176 - acc: 0.9804 - val_loss: 0.1635 - val_acc: 0.7885\n",
      "Epoch 488/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0163 - acc: 0.9804 - val_loss: 0.1489 - val_acc: 0.8269\n",
      "Epoch 489/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0169 - acc: 0.9755 - val_loss: 0.1606 - val_acc: 0.8269\n",
      "Epoch 490/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0185 - acc: 0.9755 - val_loss: 0.1579 - val_acc: 0.8077\n",
      "Epoch 491/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0171 - acc: 0.9755 - val_loss: 0.1597 - val_acc: 0.8269\n",
      "Epoch 492/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9804 - val_loss: 0.1645 - val_acc: 0.8077\n",
      "Epoch 493/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0120 - acc: 0.9853 - val_loss: 0.1600 - val_acc: 0.8077\n",
      "Epoch 494/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1591 - val_acc: 0.8077\n",
      "Epoch 495/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0107 - acc: 0.9902 - val_loss: 0.1545 - val_acc: 0.8269\n",
      "Epoch 496/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9902 - val_loss: 0.1538 - val_acc: 0.8269\n",
      "Epoch 497/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0111 - acc: 0.9853 - val_loss: 0.1553 - val_acc: 0.7885\n",
      "Epoch 498/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9853 - val_loss: 0.1480 - val_acc: 0.8269\n",
      "Epoch 499/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1338 - val_acc: 0.8654\n",
      "Epoch 500/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0283 - acc: 0.9706 - val_loss: 0.1476 - val_acc: 0.8269\n",
      "Epoch 501/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0187 - acc: 0.9804 - val_loss: 0.1535 - val_acc: 0.8269\n",
      "Epoch 502/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0149 - acc: 0.9804 - val_loss: 0.1528 - val_acc: 0.8269\n",
      "Epoch 503/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1527 - val_acc: 0.8269\n",
      "Epoch 504/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1524 - val_acc: 0.8269\n",
      "Epoch 505/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1534 - val_acc: 0.8077\n",
      "Epoch 506/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.1540 - val_acc: 0.8269\n",
      "Epoch 507/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1537 - val_acc: 0.8269\n",
      "Epoch 508/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1523 - val_acc: 0.7885\n",
      "Epoch 509/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9853 - val_loss: 0.1556 - val_acc: 0.8269\n",
      "Epoch 510/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1550 - val_acc: 0.7692\n",
      "Epoch 511/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1528 - val_acc: 0.8269\n",
      "Epoch 512/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1530 - val_acc: 0.8269\n",
      "Epoch 513/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1541 - val_acc: 0.8269\n",
      "Epoch 514/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1533 - val_acc: 0.8269\n",
      "Epoch 515/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1537 - val_acc: 0.8269\n",
      "Epoch 516/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1534 - val_acc: 0.8269\n",
      "Epoch 517/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1534 - val_acc: 0.8269\n",
      "Epoch 518/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1533 - val_acc: 0.8269\n",
      "Epoch 519/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1514 - val_acc: 0.7885\n",
      "Epoch 520/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1526 - val_acc: 0.8269\n",
      "Epoch 521/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1517 - val_acc: 0.7885\n",
      "Epoch 522/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9853 - val_loss: 0.1528 - val_acc: 0.8269\n",
      "Epoch 523/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1511 - val_acc: 0.7885\n",
      "Epoch 524/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1518 - val_acc: 0.8269\n",
      "Epoch 525/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1515 - val_acc: 0.7885\n",
      "Epoch 526/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0155 - acc: 0.9804 - val_loss: 0.1523 - val_acc: 0.8269\n",
      "Epoch 527/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1513 - val_acc: 0.7885\n",
      "Epoch 528/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9804 - val_loss: 0.1521 - val_acc: 0.8269\n",
      "Epoch 529/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1507 - val_acc: 0.7885\n",
      "Epoch 530/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9804 - val_loss: 0.1518 - val_acc: 0.8269\n",
      "Epoch 531/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1520 - val_acc: 0.8269\n",
      "Epoch 532/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1525 - val_acc: 0.8269\n",
      "Epoch 533/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1506 - val_acc: 0.7885\n",
      "Epoch 534/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.2969 - val_acc: 0.6346\n",
      "Epoch 535/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0234 - acc: 0.9706 - val_loss: 0.1541 - val_acc: 0.8269\n",
      "Epoch 536/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0167 - acc: 0.9755 - val_loss: 0.1494 - val_acc: 0.8269\n",
      "Epoch 537/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9853 - val_loss: 0.1487 - val_acc: 0.8269\n",
      "Epoch 538/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1486 - val_acc: 0.8269\n",
      "Epoch 539/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9804 - val_loss: 0.1482 - val_acc: 0.8269\n",
      "Epoch 540/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1490 - val_acc: 0.8269\n",
      "Epoch 541/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1513 - val_acc: 0.8077\n",
      "Epoch 542/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1344 - val_acc: 0.8654\n",
      "Epoch 543/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0184 - acc: 0.9853 - val_loss: 0.1533 - val_acc: 0.8269\n",
      "Epoch 544/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9853 - val_loss: 0.1541 - val_acc: 0.8077\n",
      "Epoch 545/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1543 - val_acc: 0.8077\n",
      "Epoch 546/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1670 - val_acc: 0.7692\n",
      "Epoch 547/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1609 - val_acc: 0.8077\n",
      "Epoch 548/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1578 - val_acc: 0.7885\n",
      "Epoch 549/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1570 - val_acc: 0.7885\n",
      "Epoch 550/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1617 - val_acc: 0.7885\n",
      "Epoch 551/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9853 - val_loss: 0.1621 - val_acc: 0.8077\n",
      "Epoch 552/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0127 - acc: 0.9804 - val_loss: 0.1597 - val_acc: 0.7692\n",
      "Epoch 553/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9804 - val_loss: 0.1554 - val_acc: 0.8077\n",
      "Epoch 554/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1662 - val_acc: 0.7885\n",
      "Epoch 555/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1632 - val_acc: 0.7692\n",
      "Epoch 556/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1551 - val_acc: 0.8077\n",
      "Epoch 557/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0117 - acc: 0.9853 - val_loss: 0.1598 - val_acc: 0.7692\n",
      "Epoch 558/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0112 - acc: 0.9853 - val_loss: 0.1516 - val_acc: 0.8077\n",
      "Epoch 559/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1531 - val_acc: 0.8077\n",
      "Epoch 560/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0128 - acc: 0.9804 - val_loss: 0.1482 - val_acc: 0.8269\n",
      "Epoch 561/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0112 - acc: 0.9853 - val_loss: 0.1572 - val_acc: 0.7692\n",
      "Epoch 562/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0115 - acc: 0.9853 - val_loss: 0.1472 - val_acc: 0.8269\n",
      "Epoch 563/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0130 - acc: 0.9853 - val_loss: 0.1463 - val_acc: 0.8462\n",
      "Epoch 564/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1479 - val_acc: 0.8269\n",
      "Epoch 565/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0157 - acc: 0.9804 - val_loss: 0.1477 - val_acc: 0.8269\n",
      "Epoch 566/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0118 - acc: 0.9804 - val_loss: 0.1488 - val_acc: 0.8077\n",
      "Epoch 567/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1526 - val_acc: 0.7885\n",
      "Epoch 568/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9902 - val_loss: 0.1599 - val_acc: 0.7692\n",
      "Epoch 569/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0125 - acc: 0.9853 - val_loss: 0.1599 - val_acc: 0.7692\n",
      "Epoch 570/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0113 - acc: 0.9902 - val_loss: 0.1524 - val_acc: 0.8077\n",
      "Epoch 571/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0103 - acc: 0.9902 - val_loss: 0.1500 - val_acc: 0.8077\n",
      "Epoch 572/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9755 - val_loss: 0.1480 - val_acc: 0.8269\n",
      "Epoch 573/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0116 - acc: 0.9853 - val_loss: 0.1455 - val_acc: 0.8462\n",
      "Epoch 574/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1479 - val_acc: 0.8269\n",
      "Epoch 575/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0109 - acc: 0.9853 - val_loss: 0.1570 - val_acc: 0.8077\n",
      "Epoch 576/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1488 - val_acc: 0.8077\n",
      "Epoch 577/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1376 - val_acc: 0.8654\n",
      "Epoch 578/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9853 - val_loss: 0.1424 - val_acc: 0.8269\n",
      "Epoch 579/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9902 - val_loss: 0.1448 - val_acc: 0.8269\n",
      "Epoch 580/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0102 - acc: 0.9902 - val_loss: 0.1535 - val_acc: 0.8269\n",
      "Epoch 581/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1494 - val_acc: 0.8077\n",
      "Epoch 582/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0126 - acc: 0.9804 - val_loss: 0.1477 - val_acc: 0.8077\n",
      "Epoch 583/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0100 - acc: 0.9902 - val_loss: 0.1473 - val_acc: 0.8269\n",
      "Epoch 584/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9853 - val_loss: 0.1745 - val_acc: 0.7885\n",
      "Epoch 585/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1550 - val_acc: 0.8077\n",
      "Epoch 586/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0100 - acc: 0.9902 - val_loss: 0.1656 - val_acc: 0.8077\n",
      "Epoch 587/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0108 - acc: 0.9902 - val_loss: 0.1509 - val_acc: 0.8077\n",
      "Epoch 588/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9804 - val_loss: 0.1319 - val_acc: 0.8654\n",
      "Epoch 589/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0527 - acc: 0.9461 - val_loss: 0.1492 - val_acc: 0.8077\n",
      "Epoch 590/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0213 - acc: 0.9804 - val_loss: 0.1518 - val_acc: 0.8269\n",
      "Epoch 591/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0183 - acc: 0.9804 - val_loss: 0.1517 - val_acc: 0.8269\n",
      "Epoch 592/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9853 - val_loss: 0.1518 - val_acc: 0.8077\n",
      "Epoch 593/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9853 - val_loss: 0.1502 - val_acc: 0.8269\n",
      "Epoch 594/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1511 - val_acc: 0.8269\n",
      "Epoch 595/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1578 - val_acc: 0.7885\n",
      "Epoch 596/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1619 - val_acc: 0.7885\n",
      "Epoch 597/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1602 - val_acc: 0.7885\n",
      "Epoch 598/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9804 - val_loss: 0.1475 - val_acc: 0.8269\n",
      "Epoch 599/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9853 - val_loss: 0.1515 - val_acc: 0.8269\n",
      "Epoch 600/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1527 - val_acc: 0.8269\n",
      "Epoch 601/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1545 - val_acc: 0.8462\n",
      "Epoch 602/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1592 - val_acc: 0.7885\n",
      "Epoch 603/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1649 - val_acc: 0.7885\n",
      "Epoch 604/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1551 - val_acc: 0.7885\n",
      "Epoch 605/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1547 - val_acc: 0.8077\n",
      "Epoch 606/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1598 - val_acc: 0.7885\n",
      "Epoch 607/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1621 - val_acc: 0.7885\n",
      "Epoch 608/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9853 - val_loss: 0.1562 - val_acc: 0.7885\n",
      "Epoch 609/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1555 - val_acc: 0.7885\n",
      "Epoch 610/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9853 - val_loss: 0.1539 - val_acc: 0.8269\n",
      "Epoch 611/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1559 - val_acc: 0.7885\n",
      "Epoch 612/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1601 - val_acc: 0.7885\n",
      "Epoch 613/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1564 - val_acc: 0.7885\n",
      "Epoch 614/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1604 - val_acc: 0.7885\n",
      "Epoch 615/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1615 - val_acc: 0.7885\n",
      "Epoch 616/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9804 - val_loss: 0.1561 - val_acc: 0.7885\n",
      "Epoch 617/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1599 - val_acc: 0.7885\n",
      "Epoch 618/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9853 - val_loss: 0.1569 - val_acc: 0.7885\n",
      "Epoch 619/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9853 - val_loss: 0.1537 - val_acc: 0.8269\n",
      "Epoch 620/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1551 - val_acc: 0.8269\n",
      "Epoch 621/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1560 - val_acc: 0.8077\n",
      "Epoch 622/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1564 - val_acc: 0.7885\n",
      "Epoch 623/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1594 - val_acc: 0.7885\n",
      "Epoch 624/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1446 - val_acc: 0.8462\n",
      "Epoch 625/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0162 - acc: 0.9853 - val_loss: 0.1517 - val_acc: 0.8269\n",
      "Epoch 626/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9853 - val_loss: 0.1524 - val_acc: 0.8269\n",
      "Epoch 627/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9853 - val_loss: 0.1523 - val_acc: 0.8269\n",
      "Epoch 628/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9853 - val_loss: 0.1525 - val_acc: 0.8269\n",
      "Epoch 629/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9853 - val_loss: 0.1526 - val_acc: 0.8269\n",
      "Epoch 630/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1529 - val_acc: 0.8269\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1533 - val_acc: 0.8077\n",
      "Epoch 632/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1545 - val_acc: 0.8269\n",
      "Epoch 633/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1555 - val_acc: 0.8077\n",
      "Epoch 634/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1593 - val_acc: 0.7885\n",
      "Epoch 635/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1560 - val_acc: 0.7885\n",
      "Epoch 636/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1541 - val_acc: 0.8269\n",
      "Epoch 637/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1567 - val_acc: 0.7885\n",
      "Epoch 638/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1613 - val_acc: 0.7885\n",
      "Epoch 639/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1588 - val_acc: 0.7885\n",
      "Epoch 640/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1581 - val_acc: 0.7692\n",
      "Epoch 641/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1586 - val_acc: 0.7692\n",
      "Epoch 642/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1579 - val_acc: 0.7885\n",
      "Epoch 643/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1629 - val_acc: 0.7885\n",
      "Epoch 644/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1606 - val_acc: 0.7885\n",
      "Epoch 645/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1656 - val_acc: 0.7692\n",
      "Epoch 646/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1601 - val_acc: 0.7885\n",
      "Epoch 647/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1644 - val_acc: 0.7885\n",
      "Epoch 648/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1671 - val_acc: 0.7692\n",
      "Epoch 649/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9804 - val_loss: 0.1612 - val_acc: 0.7885\n",
      "Epoch 650/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1624 - val_acc: 0.7885\n",
      "Epoch 651/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1643 - val_acc: 0.7885\n",
      "Epoch 652/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1629 - val_acc: 0.7885\n",
      "Epoch 653/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1680 - val_acc: 0.7692\n",
      "Epoch 654/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9804 - val_loss: 0.1681 - val_acc: 0.7692\n",
      "Epoch 655/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0131 - acc: 0.9853 - val_loss: 0.1770 - val_acc: 0.7692\n",
      "Epoch 656/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1675 - val_acc: 0.7885\n",
      "Epoch 657/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1461 - val_acc: 0.8462\n",
      "Epoch 658/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0169 - acc: 0.9804 - val_loss: 0.1592 - val_acc: 0.8269\n",
      "Epoch 659/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1553 - val_acc: 0.8269\n",
      "Epoch 660/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0133 - acc: 0.9804 - val_loss: 0.1558 - val_acc: 0.8269\n",
      "Epoch 661/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1558 - val_acc: 0.8269\n",
      "Epoch 662/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1558 - val_acc: 0.8269\n",
      "Epoch 663/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0130 - acc: 0.9853 - val_loss: 0.1636 - val_acc: 0.7885\n",
      "Epoch 664/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0110 - acc: 0.9902 - val_loss: 0.1569 - val_acc: 0.8269\n",
      "Epoch 665/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1697 - val_acc: 0.7885\n",
      "Epoch 666/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1657 - val_acc: 0.7885\n",
      "Epoch 667/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1725 - val_acc: 0.7885\n",
      "Epoch 668/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1693 - val_acc: 0.7885\n",
      "Epoch 669/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9804 - val_loss: 0.1760 - val_acc: 0.7885\n",
      "Epoch 670/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0113 - acc: 0.9853 - val_loss: 0.1586 - val_acc: 0.7885\n",
      "Epoch 671/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1594 - val_acc: 0.8077\n",
      "Epoch 672/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0120 - acc: 0.9853 - val_loss: 0.1778 - val_acc: 0.7885\n",
      "Epoch 673/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0120 - acc: 0.9853 - val_loss: 0.1610 - val_acc: 0.7885\n",
      "Epoch 674/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0133 - acc: 0.9804 - val_loss: 0.1613 - val_acc: 0.7885\n",
      "Epoch 675/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1812 - val_acc: 0.7885\n",
      "Epoch 676/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9755 - val_loss: 0.1689 - val_acc: 0.7885\n",
      "Epoch 677/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0104 - acc: 0.9853 - val_loss: 0.1621 - val_acc: 0.7885\n",
      "Epoch 678/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0124 - acc: 0.9853 - val_loss: 0.1628 - val_acc: 0.7885\n",
      "Epoch 679/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0104 - acc: 0.9853 - val_loss: 0.1876 - val_acc: 0.7885\n",
      "Epoch 680/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9804 - val_loss: 0.1623 - val_acc: 0.7885\n",
      "Epoch 681/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0126 - acc: 0.9804 - val_loss: 0.1434 - val_acc: 0.8462\n",
      "Epoch 682/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1433 - val_acc: 0.8462\n",
      "Epoch 683/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1445 - val_acc: 0.8462\n",
      "Epoch 684/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9804 - val_loss: 0.1451 - val_acc: 0.8462\n",
      "Epoch 685/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1479 - val_acc: 0.8269\n",
      "Epoch 686/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0116 - acc: 0.9853 - val_loss: 0.1454 - val_acc: 0.8462\n",
      "Epoch 687/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1497 - val_acc: 0.8077\n",
      "Epoch 688/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9804 - val_loss: 0.1507 - val_acc: 0.8077\n",
      "Epoch 689/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1517 - val_acc: 0.8269\n",
      "Epoch 690/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1460 - val_acc: 0.8269\n",
      "Epoch 691/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1466 - val_acc: 0.8269\n",
      "Epoch 692/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0133 - acc: 0.9804 - val_loss: 0.1499 - val_acc: 0.8077\n",
      "Epoch 693/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0100 - acc: 0.9902 - val_loss: 0.1552 - val_acc: 0.8077\n",
      "Epoch 694/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0097 - acc: 0.9902 - val_loss: 0.1528 - val_acc: 0.7885\n",
      "Epoch 695/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9902 - val_loss: 0.1610 - val_acc: 0.8269\n",
      "Epoch 696/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9902 - val_loss: 0.1556 - val_acc: 0.8077\n",
      "Epoch 697/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0099 - acc: 0.9902 - val_loss: 0.1572 - val_acc: 0.8077\n",
      "Epoch 698/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0106 - acc: 0.9853 - val_loss: 0.1450 - val_acc: 0.8462\n",
      "Epoch 699/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0124 - acc: 0.9902 - val_loss: 0.1535 - val_acc: 0.8269\n",
      "Epoch 700/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0109 - acc: 0.9902 - val_loss: 0.1539 - val_acc: 0.8269\n",
      "Epoch 701/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1543 - val_acc: 0.8269\n",
      "Epoch 702/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0118 - acc: 0.9853 - val_loss: 0.1630 - val_acc: 0.8077\n",
      "Epoch 703/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9804 - val_loss: 0.1598 - val_acc: 0.7885\n",
      "Epoch 704/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1635 - val_acc: 0.8077\n",
      "Epoch 705/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1628 - val_acc: 0.8077\n",
      "Epoch 706/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0115 - acc: 0.9853 - val_loss: 0.1549 - val_acc: 0.8269\n",
      "Epoch 707/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0120 - acc: 0.9853 - val_loss: 0.1697 - val_acc: 0.8269\n",
      "Epoch 708/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1570 - val_acc: 0.8077\n",
      "Epoch 709/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0112 - acc: 0.9853 - val_loss: 0.1736 - val_acc: 0.8269\n",
      "Epoch 710/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9804 - val_loss: 0.1765 - val_acc: 0.8077\n",
      "Epoch 711/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0125 - acc: 0.9804 - val_loss: 0.1829 - val_acc: 0.7885\n",
      "Epoch 712/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0113 - acc: 0.9804 - val_loss: 0.1613 - val_acc: 0.7885\n",
      "Epoch 713/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9804 - val_loss: 0.1612 - val_acc: 0.7885\n",
      "Epoch 714/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1789 - val_acc: 0.8077\n",
      "Epoch 715/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1748 - val_acc: 0.8269\n",
      "Epoch 716/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9902 - val_loss: 0.1741 - val_acc: 0.8077\n",
      "Epoch 717/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9853 - val_loss: 0.1701 - val_acc: 0.7885\n",
      "Epoch 718/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0089 - acc: 0.9902 - val_loss: 0.1764 - val_acc: 0.8269\n",
      "Epoch 719/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0100 - acc: 0.9853 - val_loss: 0.1721 - val_acc: 0.7885\n",
      "Epoch 720/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0088 - acc: 0.9902 - val_loss: 0.1744 - val_acc: 0.7885\n",
      "Epoch 721/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0096 - acc: 0.9853 - val_loss: 0.1739 - val_acc: 0.7885\n",
      "Epoch 722/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0095 - acc: 0.9902 - val_loss: 0.1721 - val_acc: 0.7885\n",
      "Epoch 723/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0093 - acc: 0.9902 - val_loss: 0.1709 - val_acc: 0.7885\n",
      "Epoch 724/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0097 - acc: 0.9902 - val_loss: 0.1787 - val_acc: 0.8077\n",
      "Epoch 725/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0089 - acc: 0.9853 - val_loss: 0.1733 - val_acc: 0.7885\n",
      "Epoch 726/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0102 - acc: 0.9853 - val_loss: 0.1723 - val_acc: 0.7885\n",
      "Epoch 727/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0088 - acc: 0.9902 - val_loss: 0.1759 - val_acc: 0.7885\n",
      "Epoch 728/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0084 - acc: 0.9902 - val_loss: 0.1745 - val_acc: 0.7885\n",
      "Epoch 729/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0093 - acc: 0.9902 - val_loss: 0.1835 - val_acc: 0.7885\n",
      "Epoch 730/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0090 - acc: 0.9902 - val_loss: 0.1747 - val_acc: 0.7885\n",
      "Epoch 731/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0088 - acc: 0.9902 - val_loss: 0.1796 - val_acc: 0.8077\n",
      "Epoch 732/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0099 - acc: 0.9853 - val_loss: 0.1769 - val_acc: 0.7885\n",
      "Epoch 733/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0093 - acc: 0.9902 - val_loss: 0.1505 - val_acc: 0.8462\n",
      "Epoch 734/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0118 - acc: 0.9902 - val_loss: 0.1672 - val_acc: 0.7885\n",
      "Epoch 735/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0106 - acc: 0.9902 - val_loss: 0.1633 - val_acc: 0.8077\n",
      "Epoch 736/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0110 - acc: 0.9902 - val_loss: 0.1719 - val_acc: 0.7885\n",
      "Epoch 737/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9804 - val_loss: 0.1704 - val_acc: 0.7885\n",
      "Epoch 738/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0105 - acc: 0.9902 - val_loss: 0.1670 - val_acc: 0.8077\n",
      "Epoch 739/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0120 - acc: 0.9853 - val_loss: 0.1650 - val_acc: 0.8077\n",
      "Epoch 740/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9804 - val_loss: 0.1654 - val_acc: 0.8077\n",
      "Epoch 741/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0126 - acc: 0.9853 - val_loss: 0.1762 - val_acc: 0.8077\n",
      "Epoch 742/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0118 - acc: 0.9853 - val_loss: 0.1653 - val_acc: 0.8077\n",
      "Epoch 743/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1674 - val_acc: 0.7885\n",
      "Epoch 744/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9804 - val_loss: 0.1662 - val_acc: 0.8077\n",
      "Epoch 745/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0129 - acc: 0.9853 - val_loss: 0.1748 - val_acc: 0.7885\n",
      "Epoch 746/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0111 - acc: 0.9902 - val_loss: 0.1674 - val_acc: 0.8077\n",
      "Epoch 747/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1788 - val_acc: 0.8077\n",
      "Epoch 748/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1686 - val_acc: 0.7885\n",
      "Epoch 749/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9804 - val_loss: 0.1693 - val_acc: 0.7885\n",
      "Epoch 750/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0116 - acc: 0.9853 - val_loss: 0.1800 - val_acc: 0.8077\n",
      "Epoch 751/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1690 - val_acc: 0.7885\n",
      "Epoch 752/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9853 - val_loss: 0.1791 - val_acc: 0.8077\n",
      "Epoch 753/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1693 - val_acc: 0.7885\n",
      "Epoch 754/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1810 - val_acc: 0.8077\n",
      "Epoch 755/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1345 - val_acc: 0.8654\n",
      "Epoch 756/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0369 - acc: 0.9608 - val_loss: 0.1667 - val_acc: 0.8077\n",
      "Epoch 757/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0236 - acc: 0.9755 - val_loss: 0.1673 - val_acc: 0.8077\n",
      "Epoch 758/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0212 - acc: 0.9755 - val_loss: 0.1708 - val_acc: 0.8077\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0182 - acc: 0.9804 - val_loss: 0.1666 - val_acc: 0.8077\n",
      "Epoch 760/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1664 - val_acc: 0.8077\n",
      "Epoch 761/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1645 - val_acc: 0.8077\n",
      "Epoch 762/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9853 - val_loss: 0.1651 - val_acc: 0.8077\n",
      "Epoch 763/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1638 - val_acc: 0.8077\n",
      "Epoch 764/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1672 - val_acc: 0.8077\n",
      "Epoch 765/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1668 - val_acc: 0.8077\n",
      "Epoch 766/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1674 - val_acc: 0.8077\n",
      "Epoch 767/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0151 - acc: 0.9853 - val_loss: 0.1688 - val_acc: 0.8077\n",
      "Epoch 768/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1671 - val_acc: 0.8077\n",
      "Epoch 769/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1636 - val_acc: 0.8077\n",
      "Epoch 770/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1639 - val_acc: 0.8269\n",
      "Epoch 771/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9853 - val_loss: 0.1675 - val_acc: 0.8077\n",
      "Epoch 772/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1649 - val_acc: 0.8077\n",
      "Epoch 773/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0149 - acc: 0.9804 - val_loss: 0.1681 - val_acc: 0.8077\n",
      "Epoch 774/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1698 - val_acc: 0.8077\n",
      "Epoch 775/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1697 - val_acc: 0.8077\n",
      "Epoch 776/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1698 - val_acc: 0.8077\n",
      "Epoch 777/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1713 - val_acc: 0.8077\n",
      "Epoch 778/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1705 - val_acc: 0.8077\n",
      "Epoch 779/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1702 - val_acc: 0.8077\n",
      "Epoch 780/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1666 - val_acc: 0.7885\n",
      "Epoch 781/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.2995 - val_acc: 0.6346\n",
      "Epoch 782/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0214 - acc: 0.9755 - val_loss: 0.1510 - val_acc: 0.8269\n",
      "Epoch 783/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0154 - acc: 0.9804 - val_loss: 0.1515 - val_acc: 0.8269\n",
      "Epoch 784/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1512 - val_acc: 0.8269\n",
      "Epoch 785/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0154 - acc: 0.9804 - val_loss: 0.1536 - val_acc: 0.8269\n",
      "Epoch 786/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1540 - val_acc: 0.8077\n",
      "Epoch 787/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1524 - val_acc: 0.8077\n",
      "Epoch 788/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1525 - val_acc: 0.8077\n",
      "Epoch 789/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9804 - val_loss: 0.1545 - val_acc: 0.8077\n",
      "Epoch 790/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1551 - val_acc: 0.8077\n",
      "Epoch 791/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1559 - val_acc: 0.8077\n",
      "Epoch 792/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1563 - val_acc: 0.8077\n",
      "Epoch 793/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1555 - val_acc: 0.8077\n",
      "Epoch 794/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1549 - val_acc: 0.8077\n",
      "Epoch 795/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0147 - acc: 0.9853 - val_loss: 0.1565 - val_acc: 0.8077\n",
      "Epoch 796/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1572 - val_acc: 0.8077\n",
      "Epoch 797/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1571 - val_acc: 0.8077\n",
      "Epoch 798/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1567 - val_acc: 0.8077\n",
      "Epoch 799/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1564 - val_acc: 0.7885\n",
      "Epoch 800/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9853 - val_loss: 0.1583 - val_acc: 0.8077\n",
      "Epoch 801/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0154 - acc: 0.9755 - val_loss: 0.1577 - val_acc: 0.8077\n",
      "Epoch 802/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1590 - val_acc: 0.8077\n",
      "Epoch 803/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1595 - val_acc: 0.8077\n",
      "Epoch 804/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1591 - val_acc: 0.8077\n",
      "Epoch 805/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1602 - val_acc: 0.8077\n",
      "Epoch 806/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0148 - acc: 0.9853 - val_loss: 0.1600 - val_acc: 0.8077\n",
      "Epoch 807/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1607 - val_acc: 0.8077\n",
      "Epoch 808/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1599 - val_acc: 0.7885\n",
      "Epoch 809/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1610 - val_acc: 0.7885\n",
      "Epoch 810/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1611 - val_acc: 0.7885\n",
      "Epoch 811/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1610 - val_acc: 0.7885\n",
      "Epoch 812/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1613 - val_acc: 0.7885\n",
      "Epoch 813/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1604 - val_acc: 0.7885\n",
      "Epoch 814/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1620 - val_acc: 0.7885\n",
      "Epoch 815/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1611 - val_acc: 0.7885\n",
      "Epoch 816/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1611 - val_acc: 0.7885\n",
      "Epoch 817/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1613 - val_acc: 0.7885\n",
      "Epoch 818/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1616 - val_acc: 0.7885\n",
      "Epoch 819/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1618 - val_acc: 0.7885\n",
      "Epoch 820/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1617 - val_acc: 0.7885\n",
      "Epoch 821/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1623 - val_acc: 0.7885\n",
      "Epoch 822/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9853 - val_loss: 0.1638 - val_acc: 0.7885\n",
      "Epoch 823/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1632 - val_acc: 0.7885\n",
      "Epoch 824/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1648 - val_acc: 0.7885\n",
      "Epoch 825/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1634 - val_acc: 0.7885\n",
      "Epoch 826/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1645 - val_acc: 0.7885\n",
      "Epoch 827/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1631 - val_acc: 0.8077\n",
      "Epoch 828/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1644 - val_acc: 0.8077\n",
      "Epoch 829/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1959 - val_acc: 0.7885\n",
      "Epoch 830/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9853 - val_loss: 0.1625 - val_acc: 0.8269\n",
      "Epoch 831/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0160 - acc: 0.9755 - val_loss: 0.1582 - val_acc: 0.7885\n",
      "Epoch 832/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0123 - acc: 0.9804 - val_loss: 0.1654 - val_acc: 0.7885\n",
      "Epoch 833/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0090 - acc: 0.9902 - val_loss: 0.1777 - val_acc: 0.8077\n",
      "Epoch 834/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0091 - acc: 0.9951 - val_loss: 0.1620 - val_acc: 0.7885\n",
      "Epoch 835/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0091 - acc: 0.9902 - val_loss: 0.3387 - val_acc: 0.6154\n",
      "Epoch 836/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0183 - acc: 0.9706 - val_loss: 0.1910 - val_acc: 0.7692\n",
      "Epoch 837/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1892 - val_acc: 0.7692\n",
      "Epoch 838/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9902 - val_loss: 0.1826 - val_acc: 0.7692\n",
      "Epoch 839/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0101 - acc: 0.9902 - val_loss: 0.1773 - val_acc: 0.7885\n",
      "Epoch 840/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0096 - acc: 0.9853 - val_loss: 0.1754 - val_acc: 0.7885\n",
      "Epoch 841/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0102 - acc: 0.9902 - val_loss: 0.1759 - val_acc: 0.7885\n",
      "Epoch 842/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0101 - acc: 0.9853 - val_loss: 0.1729 - val_acc: 0.7885\n",
      "Epoch 843/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1748 - val_acc: 0.7885\n",
      "Epoch 844/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0122 - acc: 0.9853 - val_loss: 0.1753 - val_acc: 0.7692\n",
      "Epoch 845/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0121 - acc: 0.9853 - val_loss: 0.1739 - val_acc: 0.7885\n",
      "Epoch 846/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0095 - acc: 0.9853 - val_loss: 0.1733 - val_acc: 0.7885\n",
      "Epoch 847/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0103 - acc: 0.9853 - val_loss: 0.1717 - val_acc: 0.7885\n",
      "Epoch 848/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9902 - val_loss: 0.1744 - val_acc: 0.7885\n",
      "Epoch 849/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0117 - acc: 0.9853 - val_loss: 0.1645 - val_acc: 0.8269\n",
      "Epoch 850/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9804 - val_loss: 0.1650 - val_acc: 0.8077\n",
      "Epoch 851/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0108 - acc: 0.9902 - val_loss: 0.1653 - val_acc: 0.7885\n",
      "Epoch 852/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0111 - acc: 0.9902 - val_loss: 0.1674 - val_acc: 0.8077\n",
      "Epoch 853/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0106 - acc: 0.9902 - val_loss: 0.1702 - val_acc: 0.8269\n",
      "Epoch 854/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0101 - acc: 0.9902 - val_loss: 0.1675 - val_acc: 0.7885\n",
      "Epoch 855/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0101 - acc: 0.9902 - val_loss: 0.1698 - val_acc: 0.8077\n",
      "Epoch 856/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0093 - acc: 0.9902 - val_loss: 0.1705 - val_acc: 0.8077\n",
      "Epoch 857/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0092 - acc: 0.9902 - val_loss: 0.1708 - val_acc: 0.8077\n",
      "Epoch 858/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0092 - acc: 0.9902 - val_loss: 0.1713 - val_acc: 0.8077\n",
      "Epoch 859/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0093 - acc: 0.9902 - val_loss: 0.1706 - val_acc: 0.7885\n",
      "Epoch 860/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0088 - acc: 0.9902 - val_loss: 0.1784 - val_acc: 0.8077\n",
      "Epoch 861/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0102 - acc: 0.9902 - val_loss: 0.1720 - val_acc: 0.7885\n",
      "Epoch 862/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0133 - acc: 0.9804 - val_loss: 0.1699 - val_acc: 0.7885\n",
      "Epoch 863/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0100 - acc: 0.9853 - val_loss: 0.1727 - val_acc: 0.7885\n",
      "Epoch 864/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0098 - acc: 0.9853 - val_loss: 0.1744 - val_acc: 0.8077\n",
      "Epoch 865/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9902 - val_loss: 0.1734 - val_acc: 0.7885\n",
      "Epoch 866/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9902 - val_loss: 0.1735 - val_acc: 0.7885\n",
      "Epoch 867/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9902 - val_loss: 0.1738 - val_acc: 0.7885\n",
      "Epoch 868/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0097 - acc: 0.9853 - val_loss: 0.1745 - val_acc: 0.7885\n",
      "Epoch 869/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0094 - acc: 0.9902 - val_loss: 0.1636 - val_acc: 0.8269\n",
      "Epoch 870/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0119 - acc: 0.9853 - val_loss: 0.1719 - val_acc: 0.7885\n",
      "Epoch 871/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1729 - val_acc: 0.7885\n",
      "Epoch 872/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1690 - val_acc: 0.8077\n",
      "Epoch 873/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1708 - val_acc: 0.7885\n",
      "Epoch 874/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1713 - val_acc: 0.7885\n",
      "Epoch 875/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9804 - val_loss: 0.1718 - val_acc: 0.7885\n",
      "Epoch 876/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0114 - acc: 0.9853 - val_loss: 0.1818 - val_acc: 0.8077\n",
      "Epoch 877/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0116 - acc: 0.9853 - val_loss: 0.1725 - val_acc: 0.7885\n",
      "Epoch 878/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9804 - val_loss: 0.1429 - val_acc: 0.8462\n",
      "Epoch 879/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0323 - acc: 0.9608 - val_loss: 0.1759 - val_acc: 0.7885\n",
      "Epoch 880/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0170 - acc: 0.9804 - val_loss: 0.1779 - val_acc: 0.7885\n",
      "Epoch 881/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9853 - val_loss: 0.1751 - val_acc: 0.8077\n",
      "Epoch 882/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.2464 - val_acc: 0.7115\n",
      "Epoch 883/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0174 - acc: 0.9804 - val_loss: 0.1735 - val_acc: 0.7885\n",
      "Epoch 884/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0150 - acc: 0.9804 - val_loss: 0.1744 - val_acc: 0.7885\n",
      "Epoch 885/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1754 - val_acc: 0.7885\n",
      "Epoch 886/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1750 - val_acc: 0.8077\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0144 - acc: 0.9804 - val_loss: 0.1771 - val_acc: 0.7885\n",
      "Epoch 888/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1771 - val_acc: 0.7885\n",
      "Epoch 889/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1763 - val_acc: 0.7885\n",
      "Epoch 890/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1680 - val_acc: 0.8077\n",
      "Epoch 891/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0152 - acc: 0.9853 - val_loss: 0.1719 - val_acc: 0.7885\n",
      "Epoch 892/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1744 - val_acc: 0.7885\n",
      "Epoch 893/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1759 - val_acc: 0.7885\n",
      "Epoch 894/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1755 - val_acc: 0.7885\n",
      "Epoch 895/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1766 - val_acc: 0.8077\n",
      "Epoch 896/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1760 - val_acc: 0.7885\n",
      "Epoch 897/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1761 - val_acc: 0.7885\n",
      "Epoch 898/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1761 - val_acc: 0.7885\n",
      "Epoch 899/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1766 - val_acc: 0.7885\n",
      "Epoch 900/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1765 - val_acc: 0.7885\n",
      "Epoch 901/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1765 - val_acc: 0.7885\n",
      "Epoch 902/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1766 - val_acc: 0.7885\n",
      "Epoch 903/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1767 - val_acc: 0.7885\n",
      "Epoch 904/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1774 - val_acc: 0.7885\n",
      "Epoch 905/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.2441 - val_acc: 0.6923\n",
      "Epoch 906/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0182 - acc: 0.9804 - val_loss: 0.1589 - val_acc: 0.8269\n",
      "Epoch 907/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0158 - acc: 0.9853 - val_loss: 0.1681 - val_acc: 0.8077\n",
      "Epoch 908/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1689 - val_acc: 0.7885\n",
      "Epoch 909/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1703 - val_acc: 0.7885\n",
      "Epoch 910/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1721 - val_acc: 0.7885\n",
      "Epoch 911/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1740 - val_acc: 0.8077\n",
      "Epoch 912/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1757 - val_acc: 0.8077\n",
      "Epoch 913/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1731 - val_acc: 0.8077\n",
      "Epoch 914/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1725 - val_acc: 0.8077\n",
      "Epoch 915/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1747 - val_acc: 0.8077\n",
      "Epoch 916/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0151 - acc: 0.9755 - val_loss: 0.1693 - val_acc: 0.7885\n",
      "Epoch 917/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1712 - val_acc: 0.7885\n",
      "Epoch 918/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1712 - val_acc: 0.7885\n",
      "Epoch 919/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1734 - val_acc: 0.8077\n",
      "Epoch 920/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1736 - val_acc: 0.8077\n",
      "Epoch 921/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9804 - val_loss: 0.1729 - val_acc: 0.7885\n",
      "Epoch 922/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0136 - acc: 0.9853 - val_loss: 0.1753 - val_acc: 0.8077\n",
      "Epoch 923/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1773 - val_acc: 0.7885\n",
      "Epoch 924/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1748 - val_acc: 0.7885\n",
      "Epoch 925/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1755 - val_acc: 0.7885\n",
      "Epoch 926/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1770 - val_acc: 0.8077\n",
      "Epoch 927/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1797 - val_acc: 0.7692\n",
      "Epoch 928/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0146 - acc: 0.9804 - val_loss: 0.1760 - val_acc: 0.8077\n",
      "Epoch 929/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.2715 - val_acc: 0.6731\n",
      "Epoch 930/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0188 - acc: 0.9804 - val_loss: 0.1788 - val_acc: 0.7885\n",
      "Epoch 931/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0162 - acc: 0.9804 - val_loss: 0.1702 - val_acc: 0.7885\n",
      "Epoch 932/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1695 - val_acc: 0.7885\n",
      "Epoch 933/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9804 - val_loss: 0.1688 - val_acc: 0.7885\n",
      "Epoch 934/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1702 - val_acc: 0.7885\n",
      "Epoch 935/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1692 - val_acc: 0.7885\n",
      "Epoch 936/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9804 - val_loss: 0.1685 - val_acc: 0.7885\n",
      "Epoch 937/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1684 - val_acc: 0.7885\n",
      "Epoch 938/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1695 - val_acc: 0.7885\n",
      "Epoch 939/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1704 - val_acc: 0.8077\n",
      "Epoch 940/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9804 - val_loss: 0.1689 - val_acc: 0.7885\n",
      "Epoch 941/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1700 - val_acc: 0.7885\n",
      "Epoch 942/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9755 - val_loss: 0.1668 - val_acc: 0.7885\n",
      "Epoch 943/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.2174 - val_acc: 0.7308\n",
      "Epoch 944/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0160 - acc: 0.9804 - val_loss: 0.1712 - val_acc: 0.7885\n",
      "Epoch 945/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0145 - acc: 0.9853 - val_loss: 0.1694 - val_acc: 0.7885\n",
      "Epoch 946/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1703 - val_acc: 0.7885\n",
      "Epoch 947/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1691 - val_acc: 0.7885\n",
      "Epoch 948/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9804 - val_loss: 0.1682 - val_acc: 0.7885\n",
      "Epoch 949/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1697 - val_acc: 0.7885\n",
      "Epoch 950/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1706 - val_acc: 0.7885\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1705 - val_acc: 0.8077\n",
      "Epoch 952/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1686 - val_acc: 0.7885\n",
      "Epoch 953/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0141 - acc: 0.9853 - val_loss: 0.1691 - val_acc: 0.7885\n",
      "Epoch 954/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1686 - val_acc: 0.7885\n",
      "Epoch 955/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1579 - val_acc: 0.8269\n",
      "Epoch 956/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0151 - acc: 0.9853 - val_loss: 0.1583 - val_acc: 0.8269\n",
      "Epoch 957/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1591 - val_acc: 0.8269\n",
      "Epoch 958/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1606 - val_acc: 0.7885\n",
      "Epoch 959/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1625 - val_acc: 0.7885\n",
      "Epoch 960/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1639 - val_acc: 0.7885\n",
      "Epoch 961/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1648 - val_acc: 0.7885\n",
      "Epoch 962/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1663 - val_acc: 0.8077\n",
      "Epoch 963/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1663 - val_acc: 0.7885\n",
      "Epoch 964/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1670 - val_acc: 0.7885\n",
      "Epoch 965/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1711 - val_acc: 0.8077\n",
      "Epoch 966/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1688 - val_acc: 0.8077\n",
      "Epoch 967/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1696 - val_acc: 0.8077\n",
      "Epoch 968/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1735 - val_acc: 0.8077\n",
      "Epoch 969/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.1731 - val_acc: 0.8077\n",
      "Epoch 970/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0140 - acc: 0.9853 - val_loss: 0.1714 - val_acc: 0.8077\n",
      "Epoch 971/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0135 - acc: 0.9853 - val_loss: 0.1744 - val_acc: 0.7885\n",
      "Epoch 972/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0130 - acc: 0.9853 - val_loss: 0.1739 - val_acc: 0.8077\n",
      "Epoch 973/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1757 - val_acc: 0.7885\n",
      "Epoch 974/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9804 - val_loss: 0.1726 - val_acc: 0.7885\n",
      "Epoch 975/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0149 - acc: 0.9853 - val_loss: 0.1688 - val_acc: 0.7885\n",
      "Epoch 976/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0137 - acc: 0.9853 - val_loss: 0.1701 - val_acc: 0.7885\n",
      "Epoch 977/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1709 - val_acc: 0.7885\n",
      "Epoch 978/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1737 - val_acc: 0.8077\n",
      "Epoch 979/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1720 - val_acc: 0.7885\n",
      "Epoch 980/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9804 - val_loss: 0.1719 - val_acc: 0.7885\n",
      "Epoch 981/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1721 - val_acc: 0.7885\n",
      "Epoch 982/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1741 - val_acc: 0.7885\n",
      "Epoch 983/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1724 - val_acc: 0.7885\n",
      "Epoch 984/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1752 - val_acc: 0.8077\n",
      "Epoch 985/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0143 - acc: 0.9853 - val_loss: 0.1725 - val_acc: 0.7885\n",
      "Epoch 986/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9804 - val_loss: 0.1727 - val_acc: 0.7885\n",
      "Epoch 987/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1723 - val_acc: 0.7885\n",
      "Epoch 988/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1726 - val_acc: 0.7885\n",
      "Epoch 989/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1728 - val_acc: 0.7885\n",
      "Epoch 990/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0139 - acc: 0.9853 - val_loss: 0.1724 - val_acc: 0.7885\n",
      "Epoch 991/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1745 - val_acc: 0.7885\n",
      "Epoch 992/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0153 - acc: 0.9755 - val_loss: 0.1703 - val_acc: 0.7885\n",
      "Epoch 993/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1715 - val_acc: 0.7885\n",
      "Epoch 994/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0134 - acc: 0.9853 - val_loss: 0.1738 - val_acc: 0.8077\n",
      "Epoch 995/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9804 - val_loss: 0.1728 - val_acc: 0.7885\n",
      "Epoch 996/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0138 - acc: 0.9853 - val_loss: 0.1728 - val_acc: 0.7885\n",
      "Epoch 997/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0133 - acc: 0.9853 - val_loss: 0.1754 - val_acc: 0.7885\n",
      "Epoch 998/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0142 - acc: 0.9853 - val_loss: 0.1735 - val_acc: 0.7885\n",
      "Epoch 999/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0132 - acc: 0.9853 - val_loss: 0.1762 - val_acc: 0.7885\n",
      "Epoch 1000/1000\n",
      "204/204 [==============================] - 0s - loss: 0.0133 - acc: 0.9853 - val_loss: 0.1775 - val_acc: 0.7885\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAAFHCAYAAAD9WFI1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b7019cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main function\n",
    "\n",
    "\n",
    "FS = \"False\"\n",
    "\n",
    "# Path to Genotype File\n",
    "G = 'genotype_PCA_30p_1200Kb.csv'\n",
    "#G = 'genotype_sub_1200Kb_1.csv'\n",
    "# Path to Phenotype File\n",
    "P = 'corrected_RYT2012DS_plotdata_by_GHID.csv'\n",
    "# Column name for trait to use in Phenotype File\n",
    "T = 'Plot_Yld'\n",
    "# Prediction method to use\n",
    "M = 'NN'    \n",
    "\n",
    "# selection percentage\n",
    "selectionPercentage = 0.3\n",
    "\n",
    " ### Data pre-processing ### \n",
    "genotype_file = pd.read_csv(G, index_col = \"Entry\")\n",
    "phenotype_file = pd.read_csv(P)\n",
    "\n",
    "# Average pheotype values for each line\n",
    "grouped = phenotype_file.groupby(['GHID'])[T].agg([np.average]).reset_index()\n",
    "grouped = grouped.set_index(\"GHID\")\n",
    "\n",
    "# Merge genotype and phenotype files by line name (GHID/Entry)\n",
    "df = pd.concat([grouped, genotype_file], axis=1, join='inner')\n",
    "\n",
    "# Drop rows that don't have trait value\n",
    "df = df.dropna(subset=[\"average\"], how = \"any\")\n",
    "\n",
    "# Make X & Y for machine learning\n",
    "X = df.drop('average', axis=1).values  \n",
    "Y = df.loc[:, 'average'].values\n",
    "\n",
    "# kf = KFold(n_splits=10, random_state = 42)   # set k-fold number\n",
    "\n",
    "  \n",
    "#if FS == \"True\" or FS == \"T\" or FS == \"true\": \n",
    "#    X = prediction.FeatSel(X,Y)\n",
    "\n",
    "# prediction\n",
    "    \n",
    "if M == \"RF\" or M == \"RandomForest\":\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    Y_TRUE, Y_PRED, Y_TRUE_train, Y_PRED_train, mse, r2 = prediction.RF(X, Y, kf)\n",
    "\n",
    "elif M == \"NN\" or M == \"NeuralNetworks\":\n",
    "    Y_max = np.max(Y)\n",
    "    Y_min = np.min(Y)\n",
    "    for i in range(0,Y.size):\n",
    "        if((Y[i]-Y_min) > (1-selectionPercentage)*(Y_max-Y_min)):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "    #print(Y)            \n",
    "    prediction.NN(X, Y)\n",
    "\n",
    "elif M == \"SVM\" or M == \"svm\":\n",
    "    from sklearn import svm\n",
    "    Y_TRUE, Y_PRED, Y_TRUE_train, Y_PRED_train, mse, r2  = prediction.SVM(X, Y, kf)\n",
    "    \n",
    "else:\n",
    "    print(\"Prediction method not available in this script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
